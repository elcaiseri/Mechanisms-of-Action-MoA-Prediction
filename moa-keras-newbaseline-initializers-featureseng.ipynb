{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03612,
     "end_time": "2020-11-23T18:57:25.357282",
     "exception": false,
     "start_time": "2020-11-23T18:57:25.321162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><h2 style='color:red'>MoA | Keras [NewBaseLine] with Features Engineering<br>Smoothing Vs Non-Smoothing</h2></center><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032365,
     "end_time": "2020-11-23T18:57:25.424473",
     "exception": false,
     "start_time": "2020-11-23T18:57:25.392108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Based on: <a href='https://www.kaggle.com/elcaiseri/moa-keras-multilabel-classifier-nn-starter'>MoA | Keras Multilabel Classifier NN | Starter </a> Kernel.\n",
    "\n",
    "\n",
    "### What is new in this Kernel?\n",
    " 1. Features Engineering, and it contains:\n",
    "- 3 SKlearn preprocessing scaler\n",
    "- Apply Rank Gauss.\n",
    "- PCA\n",
    "- SVD <== NEW\n",
    "\n",
    " 2. Feature Selection:\n",
    "- VarianceThreshold\n",
    "\n",
    " 3. Clean Data:\n",
    "- Mapping Data\n",
    "- drop train['cp_type'] column\n",
    "\n",
    " 4. Model:\n",
    "- using LeakyReLU rather than 'relu'\n",
    "- Add model smoothing\n",
    " \n",
    "* Initialize Dense Layers with \"VarianceScaling\" / \"TruncatedNormal\" ==> ' https://keras.io/api/layers/initializers/ '\n",
    "* Monitor the loss without smoothing as well and Plot the results. (From @imeintanis comment on V5)\n",
    "\n",
    "<hr><h4>Pls <span style='color:red'>UPVOTE</span>, if you find it useful. Feedbacks is also very much appreciated.<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:25.496626Z",
     "iopub.status.busy": "2020-11-23T18:57:25.495781Z",
     "iopub.status.idle": "2020-11-23T18:57:26.350185Z",
     "shell.execute_reply": "2020-11-23T18:57:26.349522Z"
    },
    "papermill": {
     "duration": 0.892874,
     "end_time": "2020-11-23T18:57:26.350307",
     "exception": false,
     "start_time": "2020-11-23T18:57:25.457433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:26.422071Z",
     "iopub.status.busy": "2020-11-23T18:57:26.420236Z",
     "iopub.status.idle": "2020-11-23T18:57:26.422767Z",
     "shell.execute_reply": "2020-11-23T18:57:26.423269Z"
    },
    "papermill": {
     "duration": 0.039969,
     "end_time": "2020-11-23T18:57:26.423384",
     "exception": false,
     "start_time": "2020-11-23T18:57:26.383415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:26.498110Z",
     "iopub.status.busy": "2020-11-23T18:57:26.497349Z",
     "iopub.status.idle": "2020-11-23T18:57:31.434535Z",
     "shell.execute_reply": "2020-11-23T18:57:31.433468Z"
    },
    "papermill": {
     "duration": 4.979366,
     "end_time": "2020-11-23T18:57:31.434699",
     "exception": false,
     "start_time": "2020-11-23T18:57:26.455333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:31.509530Z",
     "iopub.status.busy": "2020-11-23T18:57:31.508540Z",
     "iopub.status.idle": "2020-11-23T18:57:38.013716Z",
     "shell.execute_reply": "2020-11-23T18:57:38.012492Z"
    },
    "papermill": {
     "duration": 6.546714,
     "end_time": "2020-11-23T18:57:38.013866",
     "exception": false,
     "start_time": "2020-11-23T18:57:31.467152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "\n",
    "data = train_features.append(test_features)\n",
    "\n",
    "ss = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:38.088208Z",
     "iopub.status.busy": "2020-11-23T18:57:38.087545Z",
     "iopub.status.idle": "2020-11-23T18:57:39.430082Z",
     "shell.execute_reply": "2020-11-23T18:57:39.428958Z"
    },
    "papermill": {
     "duration": 1.382253,
     "end_time": "2020-11-23T18:57:39.430205",
     "exception": false,
     "start_time": "2020-11-23T18:57:38.047952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random, os, torch\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:39.505550Z",
     "iopub.status.busy": "2020-11-23T18:57:39.504752Z",
     "iopub.status.idle": "2020-11-23T18:57:40.197421Z",
     "shell.execute_reply": "2020-11-23T18:57:40.198049Z"
    },
    "papermill": {
     "duration": 0.736218,
     "end_time": "2020-11-23T18:57:40.198204",
     "exception": false,
     "start_time": "2020-11-23T18:57:39.461986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "z= np.random.randint(0, 100, size=10)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.distplot(train_features.iloc[:, z], bins=30, color='red', label='Test')\n",
    "sns.distplot(test_features.iloc[:, z], bins=30, color='green', label='Train')\n",
    "plt.legend()\n",
    "plt.title('Train / Test Distribution for z Features Before Featuring Eng.')\n",
    "plt.xlabel('z Features')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:40.280518Z",
     "iopub.status.busy": "2020-11-23T18:57:40.278630Z",
     "iopub.status.idle": "2020-11-23T18:57:40.281346Z",
     "shell.execute_reply": "2020-11-23T18:57:40.281865Z"
    },
    "papermill": {
     "duration": 0.04564,
     "end_time": "2020-11-23T18:57:40.281981",
     "exception": false,
     "start_time": "2020-11-23T18:57:40.236341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaling_ss(train, test):\n",
    "    features = train.columns[4:]\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(pd.concat([train[features], test[features]], axis = 0))\n",
    "    train[features] = scaler.transform(train[features])\n",
    "    test[features] = scaler.transform(test[features])\n",
    "    return train, test, features\n",
    "\n",
    "#train_features, test_features, features = scaling_ss(train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:40.357709Z",
     "iopub.status.busy": "2020-11-23T18:57:40.356937Z",
     "iopub.status.idle": "2020-11-23T18:57:40.360568Z",
     "shell.execute_reply": "2020-11-23T18:57:40.360079Z"
    },
    "papermill": {
     "duration": 0.044544,
     "end_time": "2020-11-23T18:57:40.360687",
     "exception": false,
     "start_time": "2020-11-23T18:57:40.316143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaling_mm(train, test):\n",
    "    features = train.columns[2:]\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(pd.concat([train[features], test[features]], axis = 0))\n",
    "    train[features] = scaler.transform(train[features])\n",
    "    test[features] = scaler.transform(test[features])\n",
    "    return train, test, features\n",
    "\n",
    "#train_features, test_features, features = scaling_mm(train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:40.441185Z",
     "iopub.status.busy": "2020-11-23T18:57:40.439910Z",
     "iopub.status.idle": "2020-11-23T18:57:49.803091Z",
     "shell.execute_reply": "2020-11-23T18:57:49.802449Z"
    },
    "papermill": {
     "duration": 9.406349,
     "end_time": "2020-11-23T18:57:49.803223",
     "exception": false,
     "start_time": "2020-11-23T18:57:40.396874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaling_rs(train, test):\n",
    "    features = train.columns[4:]\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(pd.concat([train[features], test[features]], axis = 0))\n",
    "    train[features] = scaler.transform(train[features])\n",
    "    test[features] = scaler.transform(test[features])\n",
    "    return train, test, features\n",
    "\n",
    "train_features, test_features, features = scaling_rs(train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:49.885875Z",
     "iopub.status.busy": "2020-11-23T18:57:49.884111Z",
     "iopub.status.idle": "2020-11-23T18:57:49.886565Z",
     "shell.execute_reply": "2020-11-23T18:57:49.887112Z"
    },
    "papermill": {
     "duration": 0.04425,
     "end_time": "2020-11-23T18:57:49.887231",
     "exception": false,
     "start_time": "2020-11-23T18:57:49.842981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:57:49.970925Z",
     "iopub.status.busy": "2020-11-23T18:57:49.969985Z",
     "iopub.status.idle": "2020-11-23T18:58:00.210058Z",
     "shell.execute_reply": "2020-11-23T18:58:00.209439Z"
    },
    "papermill": {
     "duration": 10.288371,
     "end_time": "2020-11-23T18:58:00.210193",
     "exception": false,
     "start_time": "2020-11-23T18:57:49.921822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RankGauss\n",
    "for col in (GENES + CELLS):\n",
    "    transformer = QuantileTransformer(n_quantiles=206,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:00.350012Z",
     "iopub.status.busy": "2020-11-23T18:58:00.348693Z",
     "iopub.status.idle": "2020-11-23T18:58:12.428953Z",
     "shell.execute_reply": "2020-11-23T18:58:12.427821Z"
    },
    "papermill": {
     "duration": 12.182368,
     "end_time": "2020-11-23T18:58:12.429085",
     "exception": false,
     "start_time": "2020-11-23T18:58:00.246717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES PCA\n",
    "n_comp = 600  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:12.509666Z",
     "iopub.status.busy": "2020-11-23T18:58:12.508415Z",
     "iopub.status.idle": "2020-11-23T18:58:13.279673Z",
     "shell.execute_reply": "2020-11-23T18:58:13.279030Z"
    },
    "papermill": {
     "duration": 0.816007,
     "end_time": "2020-11-23T18:58:13.279799",
     "exception": false,
     "start_time": "2020-11-23T18:58:12.463792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS PCA\n",
    "n_comp = 60  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:13.366231Z",
     "iopub.status.busy": "2020-11-23T18:58:13.365014Z",
     "iopub.status.idle": "2020-11-23T18:58:22.856794Z",
     "shell.execute_reply": "2020-11-23T18:58:22.856206Z"
    },
    "papermill": {
     "duration": 9.538188,
     "end_time": "2020-11-23T18:58:22.856928",
     "exception": false,
     "start_time": "2020-11-23T18:58:13.318740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES SVD\n",
    "n_comp = 450  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (TruncatedSVD(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'svd_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'svd_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:22.940774Z",
     "iopub.status.busy": "2020-11-23T18:58:22.939556Z",
     "iopub.status.idle": "2020-11-23T18:58:23.791633Z",
     "shell.execute_reply": "2020-11-23T18:58:23.791091Z"
    },
    "papermill": {
     "duration": 0.898696,
     "end_time": "2020-11-23T18:58:23.791751",
     "exception": false,
     "start_time": "2020-11-23T18:58:22.893055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS SVD\n",
    "n_comp = 45  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (TruncatedSVD(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'svd_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'svd_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:23.869512Z",
     "iopub.status.busy": "2020-11-23T18:58:23.868767Z",
     "iopub.status.idle": "2020-11-23T18:58:24.437951Z",
     "shell.execute_reply": "2020-11-23T18:58:24.437260Z"
    },
    "papermill": {
     "duration": 0.610561,
     "end_time": "2020-11-23T18:58:24.438078",
     "exception": false,
     "start_time": "2020-11-23T18:58:23.827517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c_squared(train, test):\n",
    "    \n",
    "    features_c = list(train.columns[776:876])\n",
    "    for df in [train, test]:\n",
    "        for feature in features_c:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2\n",
    "    return train, test\n",
    "\n",
    "train_features,test_features=c_squared(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:24.520192Z",
     "iopub.status.busy": "2020-11-23T18:58:24.519389Z",
     "iopub.status.idle": "2020-11-23T18:58:25.218980Z",
     "shell.execute_reply": "2020-11-23T18:58:25.217927Z"
    },
    "papermill": {
     "duration": 0.740754,
     "end_time": "2020-11-23T18:58:25.219112",
     "exception": false,
     "start_time": "2020-11-23T18:58:24.478358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c_cubed(train, test):\n",
    "    \n",
    "    features_c = list(train.columns[776:876])\n",
    "    for df in [train, test]:\n",
    "        for feature in features_c:\n",
    "            df[f'{feature}_cubed'] = df[feature] ** 3\n",
    "    return train, test\n",
    "\n",
    "train_features,test_features=c_cubed(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:25.301305Z",
     "iopub.status.busy": "2020-11-23T18:58:25.300278Z",
     "iopub.status.idle": "2020-11-23T18:58:25.567882Z",
     "shell.execute_reply": "2020-11-23T18:58:25.566836Z"
    },
    "papermill": {
     "duration": 0.312335,
     "end_time": "2020-11-23T18:58:25.568031",
     "exception": false,
     "start_time": "2020-11-23T18:58:25.255696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c_sqrt(train, test):\n",
    "    \n",
    "    features_c = list(train.columns[776:876])\n",
    "    for df in [train, test]:\n",
    "        for feature in features_c:\n",
    "            df[f'{feature}_sqrt'] = df[feature] ** 0.5\n",
    "    return train, test\n",
    "\n",
    "train_features,test_features=c_cubed(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:25.648739Z",
     "iopub.status.busy": "2020-11-23T18:58:25.647973Z",
     "iopub.status.idle": "2020-11-23T18:58:25.650980Z",
     "shell.execute_reply": "2020-11-23T18:58:25.651432Z"
    },
    "papermill": {
     "duration": 0.047843,
     "end_time": "2020-11-23T18:58:25.651564",
     "exception": false,
     "start_time": "2020-11-23T18:58:25.603721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaling_rs(train, test):\n",
    "    features = train.columns[4:]\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    scaler.fit(pd.concat([train[features], test[features]], axis = 0))\n",
    "    train[features] = scaler.transform(train[features])\n",
    "    test[features] = scaler.transform(test[features])\n",
    "    return train, test, features\n",
    "\n",
    "#train_features, test_features, features = scaling_rs(train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:25.728461Z",
     "iopub.status.busy": "2020-11-23T18:58:25.727693Z",
     "iopub.status.idle": "2020-11-23T18:58:25.732672Z",
     "shell.execute_reply": "2020-11-23T18:58:25.733439Z"
    },
    "papermill": {
     "duration": 0.046041,
     "end_time": "2020-11-23T18:58:25.733587",
     "exception": false,
     "start_time": "2020-11-23T18:58:25.687546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train/Test Features Dataset Contains [2231] Features.\n"
     ]
    }
   ],
   "source": [
    "print(f'New Train/Test Features Dataset Contains [{train_features.shape[1]}] Features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:25.814581Z",
     "iopub.status.busy": "2020-11-23T18:58:25.813957Z",
     "iopub.status.idle": "2020-11-23T18:58:25.859585Z",
     "shell.execute_reply": "2020-11-23T18:58:25.859045Z"
    },
    "papermill": {
     "duration": 0.089113,
     "end_time": "2020-11-23T18:58:25.859737",
     "exception": false,
     "start_time": "2020-11-23T18:58:25.770624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90_cubed</th>\n",
       "      <th>c-91_cubed</th>\n",
       "      <th>c-92_cubed</th>\n",
       "      <th>c-93_cubed</th>\n",
       "      <th>c-94_cubed</th>\n",
       "      <th>c-95_cubed</th>\n",
       "      <th>c-96_cubed</th>\n",
       "      <th>c-97_cubed</th>\n",
       "      <th>c-98_cubed</th>\n",
       "      <th>c-99_cubed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.135103</td>\n",
       "      <td>0.907436</td>\n",
       "      <td>-0.416008</td>\n",
       "      <td>-0.967519</td>\n",
       "      <td>-0.255730</td>\n",
       "      <td>-1.015957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069161</td>\n",
       "      <td>4.865807e-02</td>\n",
       "      <td>2.155783</td>\n",
       "      <td>0.584040</td>\n",
       "      <td>-0.013753</td>\n",
       "      <td>1.066103</td>\n",
       "      <td>-0.124268</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>0.162381</td>\n",
       "      <td>0.264380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.682081</td>\n",
       "      <td>0.272778</td>\n",
       "      <td>0.080296</td>\n",
       "      <td>1.204406</td>\n",
       "      <td>0.685582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141578</td>\n",
       "      <td>1.432816e+00</td>\n",
       "      <td>0.367403</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.069037</td>\n",
       "      <td>0.412169</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.781389</td>\n",
       "      <td>1.582357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.780157</td>\n",
       "      <td>0.946230</td>\n",
       "      <td>1.424050</td>\n",
       "      <td>-0.131333</td>\n",
       "      <td>-0.006114</td>\n",
       "      <td>1.493094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.572840</td>\n",
       "      <td>-4.057363e-01</td>\n",
       "      <td>0.865803</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-1.791560</td>\n",
       "      <td>-0.061731</td>\n",
       "      <td>-0.435982</td>\n",
       "      <td>-0.021400</td>\n",
       "      <td>-1.415513</td>\n",
       "      <td>1.295818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.735169</td>\n",
       "      <td>-0.274484</td>\n",
       "      <td>-0.438089</td>\n",
       "      <td>0.759212</td>\n",
       "      <td>2.437314</td>\n",
       "      <td>-0.859270</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.874613</td>\n",
       "      <td>-4.306504e-01</td>\n",
       "      <td>-4.489882</td>\n",
       "      <td>-1.964331</td>\n",
       "      <td>-0.849592</td>\n",
       "      <td>-1.876533</td>\n",
       "      <td>-2.327340</td>\n",
       "      <td>-0.933232</td>\n",
       "      <td>-0.113975</td>\n",
       "      <td>-0.765368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.451454</td>\n",
       "      <td>-0.476620</td>\n",
       "      <td>0.972982</td>\n",
       "      <td>0.971205</td>\n",
       "      <td>1.464785</td>\n",
       "      <td>-0.870063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.183535e-08</td>\n",
       "      <td>1.164409</td>\n",
       "      <td>4.760481</td>\n",
       "      <td>0.505106</td>\n",
       "      <td>-0.054272</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.079276</td>\n",
       "      <td>-0.106784</td>\n",
       "      <td>1.407631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.208628</td>\n",
       "      <td>-0.022182</td>\n",
       "      <td>-0.236364</td>\n",
       "      <td>-0.796853</td>\n",
       "      <td>-0.675458</td>\n",
       "      <td>0.918140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021201</td>\n",
       "      <td>3.334056e-05</td>\n",
       "      <td>-0.667344</td>\n",
       "      <td>0.131904</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>-0.065515</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>2.976468</td>\n",
       "      <td>0.478877</td>\n",
       "      <td>0.377863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.909181</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>-0.588143</td>\n",
       "      <td>1.295925</td>\n",
       "      <td>-1.003563</td>\n",
       "      <td>0.850510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249330</td>\n",
       "      <td>2.707209e-01</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>-0.058716</td>\n",
       "      <td>-0.733980</td>\n",
       "      <td>-1.134132</td>\n",
       "      <td>-0.019825</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>-0.045690</td>\n",
       "      <td>0.181156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.526208</td>\n",
       "      <td>0.631670</td>\n",
       "      <td>0.288170</td>\n",
       "      <td>-1.140025</td>\n",
       "      <td>0.768023</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519739</td>\n",
       "      <td>1.610694e-01</td>\n",
       "      <td>1.595723</td>\n",
       "      <td>0.072411</td>\n",
       "      <td>0.195422</td>\n",
       "      <td>0.991798</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>1.593636</td>\n",
       "      <td>1.063228</td>\n",
       "      <td>0.201640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.817364</td>\n",
       "      <td>0.417361</td>\n",
       "      <td>0.433126</td>\n",
       "      <td>0.300989</td>\n",
       "      <td>1.070501</td>\n",
       "      <td>-0.023311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002338</td>\n",
       "      <td>2.404564e-01</td>\n",
       "      <td>-0.015652</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>10.735543</td>\n",
       "      <td>1.339387</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>1.251610</td>\n",
       "      <td>-0.347243</td>\n",
       "      <td>0.002419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.244584</td>\n",
       "      <td>1.569426</td>\n",
       "      <td>-0.268745</td>\n",
       "      <td>1.083916</td>\n",
       "      <td>-0.511098</td>\n",
       "      <td>-2.102050</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.913409</td>\n",
       "      <td>-2.754267e+00</td>\n",
       "      <td>-5.241794</td>\n",
       "      <td>-4.390371</td>\n",
       "      <td>-5.363946</td>\n",
       "      <td>-2.160771</td>\n",
       "      <td>-3.893230</td>\n",
       "      <td>-0.196421</td>\n",
       "      <td>-2.195954</td>\n",
       "      <td>-6.332198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows  2231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose       g-0       g-1  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.135103  0.907436   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.119433  0.682081   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.780157  0.946230   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.735169 -0.274484   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.451454 -0.476620   \n",
       "...             ...          ...      ...     ...       ...       ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.208628 -0.022182   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.909181  0.585852   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.526208  0.631670   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.817364  0.417361   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -1.244584  1.569426   \n",
       "\n",
       "            g-2       g-3       g-4       g-5  ...  c-90_cubed    c-91_cubed  \\\n",
       "0     -0.416008 -0.967519 -0.255730 -1.015957  ...    0.069161  4.865807e-02   \n",
       "1      0.272778  0.080296  1.204406  0.685582  ...   -0.141578  1.432816e+00   \n",
       "2      1.424050 -0.131333 -0.006114  1.493094  ...   -0.572840 -4.057363e-01   \n",
       "3     -0.438089  0.759212  2.437314 -0.859270  ...   -2.874613 -4.306504e-01   \n",
       "4      0.972982  0.971205  1.464785 -0.870063  ...    0.000006  2.183535e-08   \n",
       "...         ...       ...       ...       ...  ...         ...           ...   \n",
       "23809 -0.236364 -0.796853 -0.675458  0.918140  ...    0.021201  3.334056e-05   \n",
       "23810 -0.588143  1.295925 -1.003563  0.850510  ...    0.249330  2.707209e-01   \n",
       "23811  0.288170 -1.140025  0.768023  0.000584  ...    0.519739  1.610694e-01   \n",
       "23812  0.433126  0.300989  1.070501 -0.023311  ...   -0.002338  2.404564e-01   \n",
       "23813 -0.268745  1.083916 -0.511098 -2.102050  ...   -3.913409 -2.754267e+00   \n",
       "\n",
       "       c-92_cubed  c-93_cubed  c-94_cubed  c-95_cubed  c-96_cubed  c-97_cubed  \\\n",
       "0        2.155783    0.584040   -0.013753    1.066103   -0.124268    0.032035   \n",
       "1        0.367403    0.000157    0.069037    0.412169    0.009312    0.005835   \n",
       "2        0.865803    0.000149   -1.791560   -0.061731   -0.435982   -0.021400   \n",
       "3       -4.489882   -1.964331   -0.849592   -1.876533   -2.327340   -0.933232   \n",
       "4        1.164409    4.760481    0.505106   -0.054272    0.003713    0.079276   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "23809   -0.667344    0.131904    0.463400   -0.065515    0.000739    2.976468   \n",
       "23810    0.000373   -0.058716   -0.733980   -1.134132   -0.019825   -0.003515   \n",
       "23811    1.595723    0.072411    0.195422    0.991798    0.031522    1.593636   \n",
       "23812   -0.015652    0.011828   10.735543    1.339387    0.013784    1.251610   \n",
       "23813   -5.241794   -4.390371   -5.363946   -2.160771   -3.893230   -0.196421   \n",
       "\n",
       "       c-98_cubed  c-99_cubed  \n",
       "0        0.162381    0.264380  \n",
       "1        0.781389    1.582357  \n",
       "2       -1.415513    1.295818  \n",
       "3       -0.113975   -0.765368  \n",
       "4       -0.106784    1.407631  \n",
       "...           ...         ...  \n",
       "23809    0.478877    0.377863  \n",
       "23810   -0.045690    0.181156  \n",
       "23811    1.063228    0.201640  \n",
       "23812   -0.347243    0.002419  \n",
       "23813   -2.195954   -6.332198  \n",
       "\n",
       "[23814 rows x 2231 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:25.949659Z",
     "iopub.status.busy": "2020-11-23T18:58:25.948360Z",
     "iopub.status.idle": "2020-11-23T18:58:27.570375Z",
     "shell.execute_reply": "2020-11-23T18:58:27.577786Z"
    },
    "papermill": {
     "duration": 1.677822,
     "end_time": "2020-11-23T18:58:27.577984",
     "exception": false,
     "start_time": "2020-11-23T18:58:25.900162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "var_thresh = VarianceThreshold(threshold)\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:27.688273Z",
     "iopub.status.busy": "2020-11-23T18:58:27.687201Z",
     "iopub.status.idle": "2020-11-23T18:58:27.691066Z",
     "shell.execute_reply": "2020-11-23T18:58:27.688884Z"
    },
    "papermill": {
     "duration": 0.054756,
     "end_time": "2020-11-23T18:58:27.691202",
     "exception": false,
     "start_time": "2020-11-23T18:58:27.636446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Threshold Select [1360] Features From [1836]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Variance Threshold Select [{train_features.shape[1]}] Features From [1836]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:27.867315Z",
     "iopub.status.busy": "2020-11-23T18:58:27.866454Z",
     "iopub.status.idle": "2020-11-23T18:58:28.281312Z",
     "shell.execute_reply": "2020-11-23T18:58:28.281956Z"
    },
    "papermill": {
     "duration": 0.538593,
     "end_time": "2020-11-23T18:58:28.282111",
     "exception": false,
     "start_time": "2020-11-23T18:58:27.743518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.copy()\n",
    "target = train_targets.copy()\n",
    "test = test_features.copy()\n",
    "\n",
    "target = target[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "target.drop(['sig_id'], axis=1, inplace=True)\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "train.drop(['sig_id', 'cp_type'], axis=1, inplace=True)\n",
    "\n",
    "test.drop(['sig_id', 'cp_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:28.445252Z",
     "iopub.status.busy": "2020-11-23T18:58:28.443350Z",
     "iopub.status.idle": "2020-11-23T18:58:39.467989Z",
     "shell.execute_reply": "2020-11-23T18:58:39.466904Z"
    },
    "papermill": {
     "duration": 11.142774,
     "end_time": "2020-11-23T18:58:39.468115",
     "exception": false,
     "start_time": "2020-11-23T18:58:28.325341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test, features = scaling_mm(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:39.552907Z",
     "iopub.status.busy": "2020-11-23T18:58:39.551510Z",
     "iopub.status.idle": "2020-11-23T18:58:39.950663Z",
     "shell.execute_reply": "2020-11-23T18:58:39.950073Z"
    },
    "papermill": {
     "duration": 0.444008,
     "end_time": "2020-11-23T18:58:39.950780",
     "exception": false,
     "start_time": "2020-11-23T18:58:39.506772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    #df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})    \n",
    "    df = pd.get_dummies(df, columns=['cp_time','cp_dose'])\n",
    "    return df\n",
    "\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)\n",
    "data = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:40.042349Z",
     "iopub.status.busy": "2020-11-23T18:58:40.036531Z",
     "iopub.status.idle": "2020-11-23T18:58:40.792019Z",
     "shell.execute_reply": "2020-11-23T18:58:40.793216Z"
    },
    "papermill": {
     "duration": 0.804937,
     "end_time": "2020-11-23T18:58:40.793441",
     "exception": false,
     "start_time": "2020-11-23T18:58:39.988504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "z= np.random.randint(0, 100, size=10)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.distplot(test.iloc[:, z], bins=30, color='red', label='Test')\n",
    "sns.distplot(train.iloc[:, z], bins=30, color='green', label='Train')\n",
    "plt.legend()\n",
    "plt.title('Train / Test Distribution for z Features After Featuring Eng.')\n",
    "plt.xlabel('z Features')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:40.930403Z",
     "iopub.status.busy": "2020-11-23T18:58:40.929428Z",
     "iopub.status.idle": "2020-11-23T18:58:40.973532Z",
     "shell.execute_reply": "2020-11-23T18:58:40.974692Z"
    },
    "papermill": {
     "duration": 0.117187,
     "end_time": "2020-11-23T18:58:40.974853",
     "exception": false,
     "start_time": "2020-11-23T18:58:40.857666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1351</th>\n",
       "      <th>1352</th>\n",
       "      <th>1353</th>\n",
       "      <th>1354</th>\n",
       "      <th>1355</th>\n",
       "      <th>cp_time_24</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "      <th>cp_dose_0</th>\n",
       "      <th>cp_dose_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.609158</td>\n",
       "      <td>0.646440</td>\n",
       "      <td>0.308137</td>\n",
       "      <td>0.406957</td>\n",
       "      <td>0.475407</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.368624</td>\n",
       "      <td>0.497608</td>\n",
       "      <td>0.565340</td>\n",
       "      <td>0.470140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503792</td>\n",
       "      <td>0.499558</td>\n",
       "      <td>0.500114</td>\n",
       "      <td>0.500578</td>\n",
       "      <td>0.500940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511485</td>\n",
       "      <td>0.622585</td>\n",
       "      <td>0.393002</td>\n",
       "      <td>0.507722</td>\n",
       "      <td>0.615823</td>\n",
       "      <td>0.565930</td>\n",
       "      <td>0.530235</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.448345</td>\n",
       "      <td>0.580527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501466</td>\n",
       "      <td>0.500033</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0.502780</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.575025</td>\n",
       "      <td>0.650547</td>\n",
       "      <td>0.534850</td>\n",
       "      <td>0.487370</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.643585</td>\n",
       "      <td>0.522639</td>\n",
       "      <td>0.535048</td>\n",
       "      <td>0.499477</td>\n",
       "      <td>0.619132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499780</td>\n",
       "      <td>0.498449</td>\n",
       "      <td>0.499924</td>\n",
       "      <td>0.494965</td>\n",
       "      <td>0.504610</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.429302</td>\n",
       "      <td>0.521326</td>\n",
       "      <td>0.305417</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.734387</td>\n",
       "      <td>0.417367</td>\n",
       "      <td>0.279287</td>\n",
       "      <td>0.529731</td>\n",
       "      <td>0.481507</td>\n",
       "      <td>0.366747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493325</td>\n",
       "      <td>0.491721</td>\n",
       "      <td>0.496680</td>\n",
       "      <td>0.499595</td>\n",
       "      <td>0.497277</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456585</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.479274</td>\n",
       "      <td>0.593397</td>\n",
       "      <td>0.640863</td>\n",
       "      <td>0.416329</td>\n",
       "      <td>0.463837</td>\n",
       "      <td>0.480302</td>\n",
       "      <td>0.397645</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499807</td>\n",
       "      <td>0.500013</td>\n",
       "      <td>0.500282</td>\n",
       "      <td>0.499620</td>\n",
       "      <td>0.505007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>0.522856</td>\n",
       "      <td>0.420212</td>\n",
       "      <td>0.386328</td>\n",
       "      <td>0.464782</td>\n",
       "      <td>0.468273</td>\n",
       "      <td>0.554743</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>0.475999</td>\n",
       "      <td>0.409579</td>\n",
       "      <td>0.497097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499892</td>\n",
       "      <td>0.497788</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.499483</td>\n",
       "      <td>0.500192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>0.520063</td>\n",
       "      <td>0.548034</td>\n",
       "      <td>0.330271</td>\n",
       "      <td>0.423370</td>\n",
       "      <td>0.435044</td>\n",
       "      <td>0.588294</td>\n",
       "      <td>0.570841</td>\n",
       "      <td>0.548845</td>\n",
       "      <td>0.440025</td>\n",
       "      <td>0.495985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499767</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.510588</td>\n",
       "      <td>0.501704</td>\n",
       "      <td>0.501344</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>0.316402</td>\n",
       "      <td>0.612398</td>\n",
       "      <td>0.286929</td>\n",
       "      <td>0.624624</td>\n",
       "      <td>0.403491</td>\n",
       "      <td>0.581790</td>\n",
       "      <td>0.470727</td>\n",
       "      <td>0.432245</td>\n",
       "      <td>0.560574</td>\n",
       "      <td>0.562117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495966</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.499987</td>\n",
       "      <td>0.499837</td>\n",
       "      <td>0.500644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>0.578603</td>\n",
       "      <td>0.594562</td>\n",
       "      <td>0.412758</td>\n",
       "      <td>0.528945</td>\n",
       "      <td>0.602946</td>\n",
       "      <td>0.497758</td>\n",
       "      <td>0.504787</td>\n",
       "      <td>0.509578</td>\n",
       "      <td>0.551006</td>\n",
       "      <td>0.385170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504765</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>0.504452</td>\n",
       "      <td>0.498765</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>0.380313</td>\n",
       "      <td>0.716516</td>\n",
       "      <td>0.326281</td>\n",
       "      <td>0.604236</td>\n",
       "      <td>0.450850</td>\n",
       "      <td>0.297854</td>\n",
       "      <td>0.343842</td>\n",
       "      <td>0.637300</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>0.620663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492313</td>\n",
       "      <td>0.486150</td>\n",
       "      <td>0.499301</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.477474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows  1361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.609158  0.646440  0.308137  0.406957  0.475407  0.402299  0.368624   \n",
       "1      0.511485  0.622585  0.393002  0.507722  0.615823  0.565930  0.530235   \n",
       "2      0.575025  0.650547  0.534850  0.487370  0.499412  0.643585  0.522639   \n",
       "3      0.429302  0.521326  0.305417  0.573010  0.734387  0.417367  0.279287   \n",
       "4      0.456585  0.499929  0.479274  0.593397  0.640863  0.416329  0.463837   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21943  0.522856  0.420212  0.386328  0.464782  0.468273  0.554743  0.485487   \n",
       "21944  0.520063  0.548034  0.330271  0.423370  0.435044  0.588294  0.570841   \n",
       "21945  0.316402  0.612398  0.286929  0.624624  0.403491  0.581790  0.470727   \n",
       "21946  0.578603  0.594562  0.412758  0.528945  0.602946  0.497758  0.504787   \n",
       "21947  0.380313  0.716516  0.326281  0.604236  0.450850  0.297854  0.343842   \n",
       "\n",
       "              7         8         9  ...      1351      1352      1353  \\\n",
       "0      0.497608  0.565340  0.470140  ...  0.503792  0.499558  0.500114   \n",
       "1      0.553500  0.448345  0.580527  ...  0.501466  0.500033  0.500021   \n",
       "2      0.535048  0.499477  0.619132  ...  0.499780  0.498449  0.499924   \n",
       "3      0.529731  0.481507  0.366747  ...  0.493325  0.491721  0.496680   \n",
       "4      0.480302  0.397645  0.581786  ...  0.499807  0.500013  0.500282   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21943  0.475999  0.409579  0.497097  ...  0.499892  0.497788  0.507937   \n",
       "21944  0.548845  0.440025  0.495985  ...  0.499767  0.500003  0.510588   \n",
       "21945  0.432245  0.560574  0.562117  ...  0.495966  0.499929  0.499987   \n",
       "21946  0.509578  0.551006  0.385170  ...  0.504765  0.500049  0.504452   \n",
       "21947  0.637300  0.718796  0.620663  ...  0.492313  0.486150  0.499301   \n",
       "\n",
       "           1354      1355  cp_time_24  cp_time_48  cp_time_72  cp_dose_0  \\\n",
       "0      0.500578  0.500940           1           0           0          1   \n",
       "1      0.502780  0.505629           0           0           1          1   \n",
       "2      0.494965  0.504610           0           1           0          1   \n",
       "3      0.499595  0.497277           0           1           0          1   \n",
       "4      0.499620  0.505007           0           0           1          0   \n",
       "...         ...       ...         ...         ...         ...        ...   \n",
       "21943  0.499483  0.500192           0           0           1          1   \n",
       "21944  0.501704  0.501344           1           0           0          0   \n",
       "21945  0.499837  0.500644           1           0           0          0   \n",
       "21946  0.498765  0.500009           1           0           0          1   \n",
       "21947  0.492188  0.477474           0           0           1          1   \n",
       "\n",
       "       cp_dose_1  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              1  \n",
       "...          ...  \n",
       "21943          0  \n",
       "21944          1  \n",
       "21945          1  \n",
       "21946          0  \n",
       "21947          0  \n",
       "\n",
       "[21948 rows x 1361 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:41.112332Z",
     "iopub.status.busy": "2020-11-23T18:58:41.110976Z",
     "iopub.status.idle": "2020-11-23T18:58:45.210006Z",
     "shell.execute_reply": "2020-11-23T18:58:45.209420Z"
    },
    "papermill": {
     "duration": 4.170665,
     "end_time": "2020-11-23T18:58:45.210165",
     "exception": false,
     "start_time": "2020-11-23T18:58:41.039500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1351</th>\n",
       "      <th>1352</th>\n",
       "      <th>1353</th>\n",
       "      <th>1354</th>\n",
       "      <th>1355</th>\n",
       "      <th>cp_time_24</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "      <th>cp_dose_0</th>\n",
       "      <th>cp_dose_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "      <td>21948.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.502042</td>\n",
       "      <td>0.552399</td>\n",
       "      <td>0.361450</td>\n",
       "      <td>0.499739</td>\n",
       "      <td>0.502718</td>\n",
       "      <td>0.499593</td>\n",
       "      <td>0.497230</td>\n",
       "      <td>0.500239</td>\n",
       "      <td>0.495345</td>\n",
       "      <td>0.498808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498518</td>\n",
       "      <td>0.491880</td>\n",
       "      <td>0.498543</td>\n",
       "      <td>0.497987</td>\n",
       "      <td>0.499309</td>\n",
       "      <td>0.326499</td>\n",
       "      <td>0.346364</td>\n",
       "      <td>0.327137</td>\n",
       "      <td>0.510115</td>\n",
       "      <td>0.489885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.096165</td>\n",
       "      <td>0.104025</td>\n",
       "      <td>0.122198</td>\n",
       "      <td>0.095595</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>0.095743</td>\n",
       "      <td>0.094417</td>\n",
       "      <td>0.094526</td>\n",
       "      <td>0.100729</td>\n",
       "      <td>0.096036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>0.066588</td>\n",
       "      <td>0.027803</td>\n",
       "      <td>0.032346</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.468943</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>0.469178</td>\n",
       "      <td>0.499909</td>\n",
       "      <td>0.499909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.436963</td>\n",
       "      <td>0.482274</td>\n",
       "      <td>0.278478</td>\n",
       "      <td>0.435310</td>\n",
       "      <td>0.439490</td>\n",
       "      <td>0.434707</td>\n",
       "      <td>0.432999</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.431393</td>\n",
       "      <td>0.433760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498728</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>0.498760</td>\n",
       "      <td>0.498677</td>\n",
       "      <td>0.498729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.501231</td>\n",
       "      <td>0.552190</td>\n",
       "      <td>0.361541</td>\n",
       "      <td>0.499457</td>\n",
       "      <td>0.501903</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.496730</td>\n",
       "      <td>0.501495</td>\n",
       "      <td>0.495936</td>\n",
       "      <td>0.498998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.565808</td>\n",
       "      <td>0.622842</td>\n",
       "      <td>0.444658</td>\n",
       "      <td>0.564038</td>\n",
       "      <td>0.565117</td>\n",
       "      <td>0.564250</td>\n",
       "      <td>0.560581</td>\n",
       "      <td>0.564089</td>\n",
       "      <td>0.560957</td>\n",
       "      <td>0.563868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500963</td>\n",
       "      <td>0.500992</td>\n",
       "      <td>0.500951</td>\n",
       "      <td>0.500884</td>\n",
       "      <td>0.500867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  1361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  21948.000000  21948.000000  21948.000000  21948.000000  21948.000000   \n",
       "mean       0.502042      0.552399      0.361450      0.499739      0.502718   \n",
       "std        0.096165      0.104025      0.122198      0.095595      0.093675   \n",
       "min        0.000000      0.000000      0.015459      0.000000      0.000000   \n",
       "25%        0.436963      0.482274      0.278478      0.435310      0.439490   \n",
       "50%        0.501231      0.552190      0.361541      0.499457      0.501903   \n",
       "75%        0.565808      0.622842      0.444658      0.564038      0.565117   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                  5             6             7             8             9  \\\n",
       "count  21948.000000  21948.000000  21948.000000  21948.000000  21948.000000   \n",
       "mean       0.499593      0.497230      0.500239      0.495345      0.498808   \n",
       "std        0.095743      0.094417      0.094526      0.100729      0.096036   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.434707      0.432999      0.437521      0.431393      0.433760   \n",
       "50%        0.499800      0.496730      0.501495      0.495936      0.498998   \n",
       "75%        0.564250      0.560581      0.564089      0.560957      0.563868   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...          1351          1352          1353          1354  \\\n",
       "count  ...  21948.000000  21948.000000  21948.000000  21948.000000   \n",
       "mean   ...      0.498518      0.491880      0.498543      0.497987   \n",
       "std    ...      0.027781      0.066588      0.027803      0.032346   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.498728      0.498758      0.498760      0.498677   \n",
       "50%    ...      0.500000      0.500000      0.500000      0.500000   \n",
       "75%    ...      0.500963      0.500992      0.500951      0.500884   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "               1355    cp_time_24    cp_time_48    cp_time_72     cp_dose_0  \\\n",
       "count  21948.000000  21948.000000  21948.000000  21948.000000  21948.000000   \n",
       "mean       0.499309      0.326499      0.346364      0.327137      0.510115   \n",
       "std        0.015929      0.468943      0.475822      0.469178      0.499909   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.498729      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.500000      0.000000      0.000000      0.000000      1.000000   \n",
       "75%        0.500867      1.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          cp_dose_1  \n",
       "count  21948.000000  \n",
       "mean       0.489885  \n",
       "std        0.499909  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 1361 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:45.300882Z",
     "iopub.status.busy": "2020-11-23T18:58:45.299678Z",
     "iopub.status.idle": "2020-11-23T18:58:45.863205Z",
     "shell.execute_reply": "2020-11-23T18:58:45.863703Z"
    },
    "papermill": {
     "duration": 0.610863,
     "end_time": "2020-11-23T18:58:45.863835",
     "exception": false,
     "start_time": "2020-11-23T18:58:45.252972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4519135339258402, 0.15778916230363557, 0.0, 1.0000000000000002)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train.values), np.std(train.values), np.min(train.values), np.max(train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:45.952968Z",
     "iopub.status.busy": "2020-11-23T18:58:45.952106Z",
     "iopub.status.idle": "2020-11-23T18:58:45.955545Z",
     "shell.execute_reply": "2020-11-23T18:58:45.956082Z"
    },
    "papermill": {
     "duration": 0.052079,
     "end_time": "2020-11-23T18:58:45.956190",
     "exception": false,
     "start_time": "2020-11-23T18:58:45.904111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somthing_rate = 1e-3\n",
    "P_MIN = somthing_rate\n",
    "P_MAX = 1 - P_MIN\n",
    "\n",
    "def loss_fn(yt, yp):\n",
    "    yp = np.clip(yp, P_MIN, P_MAX)\n",
    "    return log_loss(yt, yp, labels=[0,1])\n",
    "\n",
    "NUM_FEATURES = train.shape[1]\n",
    "NUM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:46.059776Z",
     "iopub.status.busy": "2020-11-23T18:58:46.058915Z",
     "iopub.status.idle": "2020-11-23T18:58:46.061804Z",
     "shell.execute_reply": "2020-11-23T18:58:46.061269Z"
    },
    "papermill": {
     "duration": 0.062403,
     "end_time": "2020-11-23T18:58:46.061907",
     "exception": false,
     "start_time": "2020-11-23T18:58:45.999504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(num_columns, hidden_layers=1500, SEED=None):\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Input(num_columns)])\n",
    "    #initializer = tf.keras.initializers.VarianceScaling(scale=2., mode='fan_in', distribution='truncated_normal', seed=SEED)#math.sqrt(6. / n) \n",
    "    initializer = tf.keras.initializers.TruncatedNormal(mean=0.5, stddev=1., seed=SEED) \n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    #model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tfa.layers.WeightNormalization(tf.keras.layers.Dense(hidden_layers, kernel_initializer=initializer)))\n",
    "    #model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.2654321))\n",
    "    model.add(tfa.layers.WeightNormalization(tf.keras.layers.Dense(hidden_layers, kernel_initializer=initializer)))\n",
    "    #model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    #============ Final Layer =================\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.2678923456789))\n",
    "    model.add(tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, kernel_initializer=initializer)))\n",
    "    model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "    \n",
    "    tfa_opt = tfa.optimizers.Lookahead(tfa.optimizers.AdamW(lr = 1e-2, weight_decay = 1e-5), sync_period=10)\n",
    "    tf_opt = tfa.optimizers.Lookahead(tf.keras.optimizers.Adam(learning_rate=1e-3, epsilon=1e-15), sync_period=10)\n",
    "    \n",
    "    model.compile(optimizer=tfa_opt, \n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=BinaryCrossentropy(label_smoothing=somthing_rate)\n",
    "                  )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:46.148287Z",
     "iopub.status.busy": "2020-11-23T18:58:46.147533Z",
     "iopub.status.idle": "2020-11-23T18:58:46.151510Z",
     "shell.execute_reply": "2020-11-23T18:58:46.151993Z"
    },
    "papermill": {
     "duration": 0.049203,
     "end_time": "2020-11-23T18:58:46.152119",
     "exception": false,
     "start_time": "2020-11-23T18:58:46.102916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top feats length: 1361\n"
     ]
    }
   ],
   "source": [
    "# Use All feats as top feats\n",
    "top_feats = [i for i in range(train.shape[1])]\n",
    "print(\"Top feats length:\",len(top_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:46.239459Z",
     "iopub.status.busy": "2020-11-23T18:58:46.238885Z",
     "iopub.status.idle": "2020-11-23T18:58:53.783964Z",
     "shell.execute_reply": "2020-11-23T18:58:53.785008Z"
    },
    "papermill": {
     "duration": 7.590811,
     "end_time": "2020-11-23T18:58:53.785161",
     "exception": false,
     "start_time": "2020-11-23T18:58:46.194350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 1361)              5444      \n",
      "_________________________________________________________________\n",
      "weight_normalization (Weight (None, 1500)              4087501   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1500)              6000      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "weight_normalization_1 (Weig (None, 1500)              4504501   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1500)              6000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "weight_normalization_2 (Weig (None, 206)               618619    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 206)               0         \n",
      "=================================================================\n",
      "Total params: 9,228,065\n",
      "Trainable params: 4,615,634\n",
      "Non-trainable params: 4,612,431\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = create_model(len(top_feats))\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:53.885982Z",
     "iopub.status.busy": "2020-11-23T18:58:53.885360Z",
     "iopub.status.idle": "2020-11-23T18:58:53.889818Z",
     "shell.execute_reply": "2020-11-23T18:58:53.889277Z"
    },
    "papermill": {
     "duration": 0.054777,
     "end_time": "2020-11-23T18:58:53.889918",
     "exception": false,
     "start_time": "2020-11-23T18:58:53.835141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for _target in train_targets.columns:\n",
    "        metrics.append(loss_fn(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float)))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-11-23T18:58:54.000554Z",
     "iopub.status.busy": "2020-11-23T18:58:53.999209Z",
     "iopub.status.idle": "2020-11-23T19:24:43.821950Z",
     "shell.execute_reply": "2020-11-23T19:24:43.822731Z"
    },
    "papermill": {
     "duration": 1549.887905,
     "end_time": "2020-11-23T19:24:43.822933",
     "exception": false,
     "start_time": "2020-11-23T18:58:53.935028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 0 => Fold: 0\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02359, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.1898 - binary_crossentropy: 0.1912 - val_loss: 0.0236 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02359 to 0.02279, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0213 - binary_crossentropy: 0.0240 - val_loss: 0.0228 - val_binary_crossentropy: 0.0258\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02279\n",
      "147/147 - 1s - loss: 0.0201 - binary_crossentropy: 0.0231 - val_loss: 0.0231 - val_binary_crossentropy: 0.0264\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02279 to 0.02093, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0192 - binary_crossentropy: 0.0223 - val_loss: 0.0209 - val_binary_crossentropy: 0.0243\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02093 to 0.02012, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0183 - binary_crossentropy: 0.0216 - val_loss: 0.0201 - val_binary_crossentropy: 0.0239\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02012 to 0.01771, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0177 - binary_crossentropy: 0.0210 - val_loss: 0.0177 - val_binary_crossentropy: 0.0213\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01771 to 0.01754, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0172 - binary_crossentropy: 0.0206 - val_loss: 0.0175 - val_binary_crossentropy: 0.0212\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01754 to 0.01702, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0202 - val_loss: 0.0170 - val_binary_crossentropy: 0.0206\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01702 to 0.01687, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0169 - val_binary_crossentropy: 0.0205\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01687 to 0.01657, saving model to repeat:0_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0195 - val_loss: 0.0166 - val_binary_crossentropy: 0.0202\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0154 - binary_crossentropy: 0.0191 - val_loss: 0.0169 - val_binary_crossentropy: 0.0205\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0166 - val_binary_crossentropy: 0.0203\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0145 - binary_crossentropy: 0.0183 - val_loss: 0.0166 - val_binary_crossentropy: 0.0206\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0169 - val_binary_crossentropy: 0.0206\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01657\n",
      "147/147 - 2s - loss: 0.0136 - binary_crossentropy: 0.0176 - val_loss: 0.0168 - val_binary_crossentropy: 0.0206\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0131 - binary_crossentropy: 0.0172 - val_loss: 0.0168 - val_binary_crossentropy: 0.0209\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0166 - val_loss: 0.0171 - val_binary_crossentropy: 0.0213\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0163 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0116 - binary_crossentropy: 0.0160 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0114 - binary_crossentropy: 0.0159 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0173 - val_binary_crossentropy: 0.0216\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0175 - val_binary_crossentropy: 0.0219\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01657\n",
      "147/147 - 2s - loss: 0.0103 - binary_crossentropy: 0.0150 - val_loss: 0.0174 - val_binary_crossentropy: 0.0218\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01657\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0149 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 00024: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 0 => FOLD 0 : 0.016764041519279915\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 0 => Fold: 1\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02401, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.1904 - binary_crossentropy: 0.1918 - val_loss: 0.0240 - val_binary_crossentropy: 0.0265\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02401 to 0.02277, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0228 - val_binary_crossentropy: 0.0256\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02277\n",
      "147/147 - 2s - loss: 0.0206 - binary_crossentropy: 0.0237 - val_loss: 0.0233 - val_binary_crossentropy: 0.0258\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02277 to 0.02072, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0197 - binary_crossentropy: 0.0228 - val_loss: 0.0207 - val_binary_crossentropy: 0.0239\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02072 to 0.01914, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0191 - val_binary_crossentropy: 0.0221\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01914 to 0.01868, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0187 - val_binary_crossentropy: 0.0216\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01868\n",
      "147/147 - 1s - loss: 0.0176 - binary_crossentropy: 0.0209 - val_loss: 0.0189 - val_binary_crossentropy: 0.0218\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01868 to 0.01730, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0173 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01730\n",
      "147/147 - 1s - loss: 0.0166 - binary_crossentropy: 0.0201 - val_loss: 0.0178 - val_binary_crossentropy: 0.0210\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01730 to 0.01690, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0162 - binary_crossentropy: 0.0197 - val_loss: 0.0169 - val_binary_crossentropy: 0.0203\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01690 to 0.01669, saving model to repeat:0_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0158 - binary_crossentropy: 0.0193 - val_loss: 0.0167 - val_binary_crossentropy: 0.0202\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0192 - val_loss: 0.0176 - val_binary_crossentropy: 0.0208\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0146 - binary_crossentropy: 0.0183 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0142 - binary_crossentropy: 0.0180 - val_loss: 0.0169 - val_binary_crossentropy: 0.0210\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0168 - val_binary_crossentropy: 0.0210\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0169 - val_binary_crossentropy: 0.0210\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0125 - binary_crossentropy: 0.0167 - val_loss: 0.0171 - val_binary_crossentropy: 0.0215\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0122 - binary_crossentropy: 0.0165 - val_loss: 0.0172 - val_binary_crossentropy: 0.0217\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0162 - val_loss: 0.0171 - val_binary_crossentropy: 0.0216\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0116 - binary_crossentropy: 0.0161 - val_loss: 0.0173 - val_binary_crossentropy: 0.0218\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0159 - val_loss: 0.0174 - val_binary_crossentropy: 0.0219\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0157 - val_loss: 0.0178 - val_binary_crossentropy: 0.0225\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0152 - val_loss: 0.0178 - val_binary_crossentropy: 0.0226\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01669\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0151 - val_loss: 0.0179 - val_binary_crossentropy: 0.0227\n",
      "Epoch 00025: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 0 => FOLD 1 : 0.016882385474438686\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 0 => Fold: 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02363, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.1920 - binary_crossentropy: 0.1934 - val_loss: 0.0236 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02363 to 0.02302, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0230 - val_binary_crossentropy: 0.0261\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02302\n",
      "147/147 - 1s - loss: 0.0199 - binary_crossentropy: 0.0230 - val_loss: 0.0234 - val_binary_crossentropy: 0.0269\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02302 to 0.02062, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0189 - binary_crossentropy: 0.0220 - val_loss: 0.0206 - val_binary_crossentropy: 0.0241\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02062 to 0.01819, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0182 - val_binary_crossentropy: 0.0217\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01819 to 0.01761, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0176 - val_binary_crossentropy: 0.0211\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01761 to 0.01757, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0176 - val_binary_crossentropy: 0.0213\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01757 to 0.01721, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0164 - binary_crossentropy: 0.0199 - val_loss: 0.0172 - val_binary_crossentropy: 0.0209\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01721\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0195 - val_loss: 0.0179 - val_binary_crossentropy: 0.0220\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01721\n",
      "147/147 - 1s - loss: 0.0156 - binary_crossentropy: 0.0192 - val_loss: 0.0177 - val_binary_crossentropy: 0.0217\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01721 to 0.01708, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0146 - binary_crossentropy: 0.0184 - val_loss: 0.0172 - val_binary_crossentropy: 0.0212\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01708 to 0.01679, saving model to repeat:0_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0142 - binary_crossentropy: 0.0181 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0171 - val_binary_crossentropy: 0.0212\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0133 - binary_crossentropy: 0.0174 - val_loss: 0.0173 - val_binary_crossentropy: 0.0216\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0166 - val_loss: 0.0178 - val_binary_crossentropy: 0.0222\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0163 - val_loss: 0.0180 - val_binary_crossentropy: 0.0227\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01679\n",
      "147/147 - 2s - loss: 0.0114 - binary_crossentropy: 0.0161 - val_loss: 0.0186 - val_binary_crossentropy: 0.0236\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01679\n",
      "147/147 - 2s - loss: 0.0105 - binary_crossentropy: 0.0152 - val_loss: 0.0179 - val_binary_crossentropy: 0.0225\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0183 - val_binary_crossentropy: 0.0229\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0147 - val_loss: 0.0185 - val_binary_crossentropy: 0.0232\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0146 - val_loss: 0.0186 - val_binary_crossentropy: 0.0234\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0092 - binary_crossentropy: 0.0144 - val_loss: 0.0191 - val_binary_crossentropy: 0.0240\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0089 - binary_crossentropy: 0.0143 - val_loss: 0.0192 - val_binary_crossentropy: 0.0244\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01679\n",
      "147/147 - 1s - loss: 0.0085 - binary_crossentropy: 0.0140 - val_loss: 0.0191 - val_binary_crossentropy: 0.0242\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01679\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0083 - binary_crossentropy: 0.0138 - val_loss: 0.0194 - val_binary_crossentropy: 0.0245\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 0 => FOLD 2 : 0.016895051407745592\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 0 => Fold: 3\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02355, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.1869 - binary_crossentropy: 0.1883 - val_loss: 0.0236 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02355 to 0.02284, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0228 - val_binary_crossentropy: 0.0258\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02284\n",
      "147/147 - 1s - loss: 0.0202 - binary_crossentropy: 0.0232 - val_loss: 0.0231 - val_binary_crossentropy: 0.0264\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02284\n",
      "147/147 - 1s - loss: 0.0193 - binary_crossentropy: 0.0225 - val_loss: 0.0229 - val_binary_crossentropy: 0.0267\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02284 to 0.01921, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0184 - binary_crossentropy: 0.0217 - val_loss: 0.0192 - val_binary_crossentropy: 0.0229\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01921 to 0.01768, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0177 - binary_crossentropy: 0.0210 - val_loss: 0.0177 - val_binary_crossentropy: 0.0212\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01768\n",
      "147/147 - 1s - loss: 0.0172 - binary_crossentropy: 0.0206 - val_loss: 0.0177 - val_binary_crossentropy: 0.0213\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01768 to 0.01719, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0202 - val_loss: 0.0172 - val_binary_crossentropy: 0.0208\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01719 to 0.01707, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0171 - val_binary_crossentropy: 0.0207\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01707 to 0.01667, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0194 - val_loss: 0.0167 - val_binary_crossentropy: 0.0202\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01667\n",
      "147/147 - 2s - loss: 0.0154 - binary_crossentropy: 0.0191 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01667 to 0.01657, saving model to repeat:0_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0166 - val_binary_crossentropy: 0.0203\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0145 - binary_crossentropy: 0.0183 - val_loss: 0.0166 - val_binary_crossentropy: 0.0206\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0136 - binary_crossentropy: 0.0176 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0131 - binary_crossentropy: 0.0173 - val_loss: 0.0171 - val_binary_crossentropy: 0.0213\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0124 - binary_crossentropy: 0.0166 - val_loss: 0.0170 - val_binary_crossentropy: 0.0210\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0163 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0117 - binary_crossentropy: 0.0161 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0114 - binary_crossentropy: 0.0159 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0157 - val_loss: 0.0176 - val_binary_crossentropy: 0.0219\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0108 - binary_crossentropy: 0.0155 - val_loss: 0.0179 - val_binary_crossentropy: 0.0223\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0178 - val_binary_crossentropy: 0.0222\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0179 - val_binary_crossentropy: 0.0224\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0149 - val_loss: 0.0180 - val_binary_crossentropy: 0.0225\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01657\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0148 - val_loss: 0.0182 - val_binary_crossentropy: 0.0227\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 0 => FOLD 3 : 0.016676709627146805\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 0 => Fold: 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02374, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.1882 - binary_crossentropy: 0.1896 - val_loss: 0.0237 - val_binary_crossentropy: 0.0263\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02374 to 0.02302, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0230 - val_binary_crossentropy: 0.0260\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02302 to 0.02289, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0202 - binary_crossentropy: 0.0232 - val_loss: 0.0229 - val_binary_crossentropy: 0.0260\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02289 to 0.02128, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0193 - binary_crossentropy: 0.0224 - val_loss: 0.0213 - val_binary_crossentropy: 0.0247\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02128 to 0.01899, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0185 - binary_crossentropy: 0.0217 - val_loss: 0.0190 - val_binary_crossentropy: 0.0225\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01899 to 0.01807, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0177 - binary_crossentropy: 0.0211 - val_loss: 0.0181 - val_binary_crossentropy: 0.0216\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01807 to 0.01788, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0172 - binary_crossentropy: 0.0206 - val_loss: 0.0179 - val_binary_crossentropy: 0.0214\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01788 to 0.01766, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0168 - binary_crossentropy: 0.0202 - val_loss: 0.0177 - val_binary_crossentropy: 0.0215\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01766 to 0.01730, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0173 - val_binary_crossentropy: 0.0210\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01730\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0195 - val_loss: 0.0174 - val_binary_crossentropy: 0.0212\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01730 to 0.01710, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0191 - val_loss: 0.0171 - val_binary_crossentropy: 0.0208\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01710 to 0.01708, saving model to repeat:0_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0171 - val_binary_crossentropy: 0.0209\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0146 - binary_crossentropy: 0.0184 - val_loss: 0.0172 - val_binary_crossentropy: 0.0212\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0174 - val_binary_crossentropy: 0.0217\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0175 - val_binary_crossentropy: 0.0217\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0163 - val_loss: 0.0174 - val_binary_crossentropy: 0.0215\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0116 - binary_crossentropy: 0.0160 - val_loss: 0.0174 - val_binary_crossentropy: 0.0216\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0158 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0154 - val_loss: 0.0181 - val_binary_crossentropy: 0.0225\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0152 - val_loss: 0.0181 - val_binary_crossentropy: 0.0226\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0149 - val_loss: 0.0183 - val_binary_crossentropy: 0.0229\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0147 - val_loss: 0.0183 - val_binary_crossentropy: 0.0230\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01708\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0146 - val_loss: 0.0184 - val_binary_crossentropy: 0.0231\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 0 => FOLD 4 : 0.017093244654035666\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 0 => Fold: 5\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02408, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.1923 - binary_crossentropy: 0.1937 - val_loss: 0.0241 - val_binary_crossentropy: 0.0265\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02408 to 0.02281, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0228 - val_binary_crossentropy: 0.0255\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02281 to 0.02276, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0202 - binary_crossentropy: 0.0233 - val_loss: 0.0228 - val_binary_crossentropy: 0.0254\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02276\n",
      "147/147 - 1s - loss: 0.0193 - binary_crossentropy: 0.0224 - val_loss: 0.0254 - val_binary_crossentropy: 0.0280\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02276 to 0.02017, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0184 - binary_crossentropy: 0.0216 - val_loss: 0.0202 - val_binary_crossentropy: 0.0232\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02017 to 0.01789, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0177 - binary_crossentropy: 0.0210 - val_loss: 0.0179 - val_binary_crossentropy: 0.0210\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01789 to 0.01752, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0172 - binary_crossentropy: 0.0206 - val_loss: 0.0175 - val_binary_crossentropy: 0.0207\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01752 to 0.01749, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0168 - binary_crossentropy: 0.0202 - val_loss: 0.0175 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01749 to 0.01702, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0170 - val_binary_crossentropy: 0.0204\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01702\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0194 - val_loss: 0.0170 - val_binary_crossentropy: 0.0204\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01702\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0191 - val_loss: 0.0171 - val_binary_crossentropy: 0.0207\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01702 to 0.01671, saving model to repeat:0_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0149 - binary_crossentropy: 0.0187 - val_loss: 0.0182 - val_binary_crossentropy: 0.0214\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0181 - val_loss: 0.0170 - val_binary_crossentropy: 0.0206\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01671\n",
      "147/147 - 2s - loss: 0.0138 - binary_crossentropy: 0.0177 - val_loss: 0.0170 - val_binary_crossentropy: 0.0210\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0133 - binary_crossentropy: 0.0173 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0176 - val_binary_crossentropy: 0.0220\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0124 - binary_crossentropy: 0.0167 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01671\n",
      "147/147 - 2s - loss: 0.0115 - binary_crossentropy: 0.0160 - val_loss: 0.0175 - val_binary_crossentropy: 0.0220\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0157 - val_loss: 0.0179 - val_binary_crossentropy: 0.0225\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0155 - val_loss: 0.0180 - val_binary_crossentropy: 0.0226\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0180 - val_binary_crossentropy: 0.0227\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0152 - val_loss: 0.0184 - val_binary_crossentropy: 0.0233\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0187 - val_binary_crossentropy: 0.0236\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01671\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0146 - val_loss: 0.0186 - val_binary_crossentropy: 0.0235\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01671\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0095 - binary_crossentropy: 0.0146 - val_loss: 0.0186 - val_binary_crossentropy: 0.0235\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 0 => FOLD 5 : 0.016850860257328876\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 0 => Fold: 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02364, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.1867 - binary_crossentropy: 0.1882 - val_loss: 0.0236 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02364 to 0.02303, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0239 - val_loss: 0.0230 - val_binary_crossentropy: 0.0261\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02303\n",
      "147/147 - 1s - loss: 0.0199 - binary_crossentropy: 0.0229 - val_loss: 0.0234 - val_binary_crossentropy: 0.0269\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02303 to 0.02049, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0189 - binary_crossentropy: 0.0221 - val_loss: 0.0205 - val_binary_crossentropy: 0.0239\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02049 to 0.01828, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0181 - binary_crossentropy: 0.0214 - val_loss: 0.0183 - val_binary_crossentropy: 0.0217\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01828 to 0.01824, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0175 - binary_crossentropy: 0.0208 - val_loss: 0.0182 - val_binary_crossentropy: 0.0219\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01824 to 0.01756, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0176 - val_binary_crossentropy: 0.0212\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01756 to 0.01701, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0166 - binary_crossentropy: 0.0201 - val_loss: 0.0170 - val_binary_crossentropy: 0.0205\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01701 to 0.01678, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0161 - binary_crossentropy: 0.0196 - val_loss: 0.0168 - val_binary_crossentropy: 0.0204\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01678 to 0.01676, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0168 - val_binary_crossentropy: 0.0205\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01676 to 0.01668, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0167 - val_binary_crossentropy: 0.0203\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01668\n",
      "147/147 - 2s - loss: 0.0148 - binary_crossentropy: 0.0186 - val_loss: 0.0171 - val_binary_crossentropy: 0.0212\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01668\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01668\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0179 - val_loss: 0.0175 - val_binary_crossentropy: 0.0218\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01668\n",
      "147/147 - 1s - loss: 0.0135 - binary_crossentropy: 0.0175 - val_loss: 0.0169 - val_binary_crossentropy: 0.0209\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01668 to 0.01664, saving model to repeat:0_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0127 - binary_crossentropy: 0.0169 - val_loss: 0.0166 - val_binary_crossentropy: 0.0206\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0166 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0120 - binary_crossentropy: 0.0163 - val_loss: 0.0174 - val_binary_crossentropy: 0.0217\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0162 - val_loss: 0.0171 - val_binary_crossentropy: 0.0214\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0114 - binary_crossentropy: 0.0159 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0157 - val_loss: 0.0176 - val_binary_crossentropy: 0.0221\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0156 - val_loss: 0.0175 - val_binary_crossentropy: 0.0219\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0151 - val_loss: 0.0175 - val_binary_crossentropy: 0.0219\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01664\n",
      "147/147 - 2s - loss: 0.0102 - binary_crossentropy: 0.0150 - val_loss: 0.0176 - val_binary_crossentropy: 0.0221\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01664\n",
      "147/147 - 2s - loss: 0.0100 - binary_crossentropy: 0.0149 - val_loss: 0.0178 - val_binary_crossentropy: 0.0225\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0148 - val_loss: 0.0179 - val_binary_crossentropy: 0.0224\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0147 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0147 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0144 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01664\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0092 - binary_crossentropy: 0.0144 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 00030: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 0 => FOLD 6 : 0.01674435128905074\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 1 => Fold: 0\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02439, saving model to repeat:1_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.1902 - binary_crossentropy: 0.1916 - val_loss: 0.0244 - val_binary_crossentropy: 0.0269\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02439 to 0.02298, saving model to repeat:1_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0230 - val_binary_crossentropy: 0.0258\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02298\n",
      "147/147 - 1s - loss: 0.0210 - binary_crossentropy: 0.0240 - val_loss: 0.0242 - val_binary_crossentropy: 0.0267\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02298 to 0.02190, saving model to repeat:1_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0202 - binary_crossentropy: 0.0233 - val_loss: 0.0219 - val_binary_crossentropy: 0.0255\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02190 to 0.02107, saving model to repeat:1_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0193 - binary_crossentropy: 0.0225 - val_loss: 0.0211 - val_binary_crossentropy: 0.0246\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02107\n",
      "147/147 - 1s - loss: 0.0184 - binary_crossentropy: 0.0216 - val_loss: 0.0219 - val_binary_crossentropy: 0.0248\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02107 to 0.01822, saving model to repeat:1_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0177 - binary_crossentropy: 0.0210 - val_loss: 0.0182 - val_binary_crossentropy: 0.0214\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01822\n",
      "147/147 - 1s - loss: 0.0172 - binary_crossentropy: 0.0205 - val_loss: 0.0276 - val_binary_crossentropy: 0.0308\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01822 to 0.01742, saving model to repeat:1_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0201 - val_loss: 0.0174 - val_binary_crossentropy: 0.0208\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01742\n",
      "147/147 - 1s - loss: 0.0163 - binary_crossentropy: 0.0197 - val_loss: 0.0174 - val_binary_crossentropy: 0.0211\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01742\n",
      "147/147 - 1s - loss: 0.0158 - binary_crossentropy: 0.0193 - val_loss: 0.0177 - val_binary_crossentropy: 0.0215\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01742 to 0.01717, saving model to repeat:1_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0154 - binary_crossentropy: 0.0190 - val_loss: 0.0172 - val_binary_crossentropy: 0.0208\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0173 - val_binary_crossentropy: 0.0211\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0145 - binary_crossentropy: 0.0183 - val_loss: 0.0174 - val_binary_crossentropy: 0.0213\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0174 - val_binary_crossentropy: 0.0214\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0156 - binary_crossentropy: 0.0193 - val_loss: 0.0804 - val_binary_crossentropy: 0.0825\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0142 - binary_crossentropy: 0.0181 - val_loss: 0.0192 - val_binary_crossentropy: 0.0238\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0136 - binary_crossentropy: 0.0176 - val_loss: 0.0197 - val_binary_crossentropy: 0.0245\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01717\n",
      "147/147 - 2s - loss: 0.0130 - binary_crossentropy: 0.0171 - val_loss: 0.0187 - val_binary_crossentropy: 0.0234\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0169 - val_loss: 0.0178 - val_binary_crossentropy: 0.0221\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0125 - binary_crossentropy: 0.0167 - val_loss: 0.0180 - val_binary_crossentropy: 0.0224\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0166 - val_loss: 0.0180 - val_binary_crossentropy: 0.0224\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0121 - binary_crossentropy: 0.0165 - val_loss: 0.0181 - val_binary_crossentropy: 0.0227\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0163 - val_loss: 0.0184 - val_binary_crossentropy: 0.0231\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01717\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0160 - val_loss: 0.0182 - val_binary_crossentropy: 0.0228\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01717\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0114 - binary_crossentropy: 0.0159 - val_loss: 0.0180 - val_binary_crossentropy: 0.0226\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 1 => FOLD 0 : 0.017266303307781183\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 1 => Fold: 1\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02396, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.1905 - binary_crossentropy: 0.1919 - val_loss: 0.0240 - val_binary_crossentropy: 0.0264\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02396 to 0.02273, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0227 - val_binary_crossentropy: 0.0255\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02273\n",
      "147/147 - 1s - loss: 0.0211 - binary_crossentropy: 0.0241 - val_loss: 0.0407 - val_binary_crossentropy: 0.0424\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02273 to 0.02194, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0202 - binary_crossentropy: 0.0233 - val_loss: 0.0219 - val_binary_crossentropy: 0.0247\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02194 to 0.02033, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0192 - binary_crossentropy: 0.0224 - val_loss: 0.0203 - val_binary_crossentropy: 0.0232\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02033 to 0.01849, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0185 - binary_crossentropy: 0.0217 - val_loss: 0.0185 - val_binary_crossentropy: 0.0216\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01849 to 0.01772, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0179 - binary_crossentropy: 0.0212 - val_loss: 0.0177 - val_binary_crossentropy: 0.0209\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01772 to 0.01743, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0175 - binary_crossentropy: 0.0208 - val_loss: 0.0174 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01743\n",
      "147/147 - 1s - loss: 0.0171 - binary_crossentropy: 0.0204 - val_loss: 0.0193 - val_binary_crossentropy: 0.0225\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01743 to 0.01705, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0168 - binary_crossentropy: 0.0202 - val_loss: 0.0170 - val_binary_crossentropy: 0.0204\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01705 to 0.01692, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0169 - val_binary_crossentropy: 0.0202\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0195 - val_loss: 0.0170 - val_binary_crossentropy: 0.0207\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01692 to 0.01671, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0156 - binary_crossentropy: 0.0192 - val_loss: 0.0167 - val_binary_crossentropy: 0.0203\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01671 to 0.01664, saving model to repeat:1_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0166 - val_binary_crossentropy: 0.0203\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0148 - binary_crossentropy: 0.0185 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0178 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0135 - binary_crossentropy: 0.0175 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0130 - binary_crossentropy: 0.0171 - val_loss: 0.0171 - val_binary_crossentropy: 0.0212\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0165 - val_loss: 0.0170 - val_binary_crossentropy: 0.0213\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0162 - val_loss: 0.0173 - val_binary_crossentropy: 0.0216\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0117 - binary_crossentropy: 0.0160 - val_loss: 0.0173 - val_binary_crossentropy: 0.0216\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0158 - val_loss: 0.0176 - val_binary_crossentropy: 0.0220\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0156 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0108 - binary_crossentropy: 0.0155 - val_loss: 0.0180 - val_binary_crossentropy: 0.0227\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0151 - val_loss: 0.0181 - val_binary_crossentropy: 0.0229\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01664\n",
      "147/147 - 2s - loss: 0.0101 - binary_crossentropy: 0.0149 - val_loss: 0.0180 - val_binary_crossentropy: 0.0227\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01664\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0149 - val_loss: 0.0182 - val_binary_crossentropy: 0.0230\n",
      "Epoch 00028: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 1 => FOLD 1 : 0.016792008070953816\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 1 => Fold: 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02338, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.1940 - binary_crossentropy: 0.1954 - val_loss: 0.0234 - val_binary_crossentropy: 0.0260\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02338 to 0.02287, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0229 - val_binary_crossentropy: 0.0260\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02287\n",
      "147/147 - 1s - loss: 0.0199 - binary_crossentropy: 0.0229 - val_loss: 0.0230 - val_binary_crossentropy: 0.0264\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02287 to 0.02033, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0203 - val_binary_crossentropy: 0.0238\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02033 to 0.01835, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0184 - val_binary_crossentropy: 0.0219\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01835 to 0.01769, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0207 - val_loss: 0.0177 - val_binary_crossentropy: 0.0211\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01769 to 0.01724, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0172 - val_binary_crossentropy: 0.0208\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01724 to 0.01702, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0165 - binary_crossentropy: 0.0199 - val_loss: 0.0170 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01702 to 0.01686, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0196 - val_loss: 0.0169 - val_binary_crossentropy: 0.0205\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01686 to 0.01673, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0156 - binary_crossentropy: 0.0192 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01673\n",
      "147/147 - 2s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0173 - val_binary_crossentropy: 0.0214\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01673\n",
      "147/147 - 2s - loss: 0.0147 - binary_crossentropy: 0.0185 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01673 to 0.01653, saving model to repeat:1_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0181 - val_loss: 0.0165 - val_binary_crossentropy: 0.0205\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0138 - binary_crossentropy: 0.0178 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0133 - binary_crossentropy: 0.0174 - val_loss: 0.0169 - val_binary_crossentropy: 0.0211\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0170 - val_binary_crossentropy: 0.0213\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0124 - binary_crossentropy: 0.0167 - val_loss: 0.0175 - val_binary_crossentropy: 0.0219\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0163 - val_loss: 0.0184 - val_binary_crossentropy: 0.0232\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0114 - binary_crossentropy: 0.0160 - val_loss: 0.0182 - val_binary_crossentropy: 0.0231\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0153 - val_loss: 0.0181 - val_binary_crossentropy: 0.0229\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0102 - binary_crossentropy: 0.0150 - val_loss: 0.0179 - val_binary_crossentropy: 0.0225\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0148 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0147 - val_loss: 0.0183 - val_binary_crossentropy: 0.0232\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0146 - val_loss: 0.0187 - val_binary_crossentropy: 0.0236\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0091 - binary_crossentropy: 0.0144 - val_loss: 0.0188 - val_binary_crossentropy: 0.0239\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0086 - binary_crossentropy: 0.0140 - val_loss: 0.0190 - val_binary_crossentropy: 0.0242\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01653\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 2s - loss: 0.0084 - binary_crossentropy: 0.0139 - val_loss: 0.0192 - val_binary_crossentropy: 0.0244\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 1 => FOLD 2 : 0.016655216709911793\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 1 => Fold: 3\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02410, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.1870 - binary_crossentropy: 0.1884 - val_loss: 0.0241 - val_binary_crossentropy: 0.0266\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02410 to 0.02271, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0227 - val_binary_crossentropy: 0.0255\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02271 to 0.02219, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0201 - binary_crossentropy: 0.0231 - val_loss: 0.0222 - val_binary_crossentropy: 0.0249\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02219\n",
      "147/147 - 1s - loss: 0.0195 - binary_crossentropy: 0.0226 - val_loss: 0.0235 - val_binary_crossentropy: 0.0261\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02219 to 0.01814, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0184 - binary_crossentropy: 0.0216 - val_loss: 0.0181 - val_binary_crossentropy: 0.0213\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01814 to 0.01764, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0181 - binary_crossentropy: 0.0213 - val_loss: 0.0176 - val_binary_crossentropy: 0.0209\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01764\n",
      "147/147 - 1s - loss: 0.0173 - binary_crossentropy: 0.0206 - val_loss: 0.0179 - val_binary_crossentropy: 0.0211\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01764 to 0.01719, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0172 - val_binary_crossentropy: 0.0204\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01719 to 0.01700, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0165 - binary_crossentropy: 0.0199 - val_loss: 0.0170 - val_binary_crossentropy: 0.0203\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01700\n",
      "147/147 - 2s - loss: 0.0161 - binary_crossentropy: 0.0196 - val_loss: 0.0171 - val_binary_crossentropy: 0.0203\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01700 to 0.01695, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0156 - binary_crossentropy: 0.0192 - val_loss: 0.0170 - val_binary_crossentropy: 0.0203\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01695 to 0.01670, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0152 - binary_crossentropy: 0.0188 - val_loss: 0.0167 - val_binary_crossentropy: 0.0203\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01670 to 0.01658, saving model to repeat:1_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0148 - binary_crossentropy: 0.0185 - val_loss: 0.0166 - val_binary_crossentropy: 0.0204\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0144 - binary_crossentropy: 0.0182 - val_loss: 0.0169 - val_binary_crossentropy: 0.0211\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0178 - val_loss: 0.0168 - val_binary_crossentropy: 0.0206\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0174 - val_loss: 0.0168 - val_binary_crossentropy: 0.0210\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0129 - binary_crossentropy: 0.0171 - val_loss: 0.0172 - val_binary_crossentropy: 0.0216\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0125 - binary_crossentropy: 0.0167 - val_loss: 0.0172 - val_binary_crossentropy: 0.0215\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01658\n",
      "147/147 - 2s - loss: 0.0120 - binary_crossentropy: 0.0164 - val_loss: 0.0172 - val_binary_crossentropy: 0.0217\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0157 - val_loss: 0.0174 - val_binary_crossentropy: 0.0219\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0108 - binary_crossentropy: 0.0154 - val_loss: 0.0178 - val_binary_crossentropy: 0.0225\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0105 - binary_crossentropy: 0.0152 - val_loss: 0.0180 - val_binary_crossentropy: 0.0228\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01658\n",
      "147/147 - 2s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0182 - val_binary_crossentropy: 0.0231\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0150 - val_loss: 0.0186 - val_binary_crossentropy: 0.0237\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01658\n",
      "147/147 - 2s - loss: 0.0097 - binary_crossentropy: 0.0148 - val_loss: 0.0187 - val_binary_crossentropy: 0.0239\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01658\n",
      "147/147 - 2s - loss: 0.0093 - binary_crossentropy: 0.0144 - val_loss: 0.0185 - val_binary_crossentropy: 0.0236\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01658\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0091 - binary_crossentropy: 0.0143 - val_loss: 0.0189 - val_binary_crossentropy: 0.0242\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 1 => FOLD 3 : 0.0167157836956796\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 1 => Fold: 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02347, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.1847 - binary_crossentropy: 0.1861 - val_loss: 0.0235 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02347 to 0.02294, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0211 - binary_crossentropy: 0.0239 - val_loss: 0.0229 - val_binary_crossentropy: 0.0261\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02294\n",
      "147/147 - 1s - loss: 0.0198 - binary_crossentropy: 0.0228 - val_loss: 0.0233 - val_binary_crossentropy: 0.0268\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02294 to 0.02233, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0223 - val_binary_crossentropy: 0.0263\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02233 to 0.02031, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0203 - val_binary_crossentropy: 0.0244\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02031 to 0.01808, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0181 - val_binary_crossentropy: 0.0220\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01808\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0187 - val_binary_crossentropy: 0.0228\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01808 to 0.01733, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0164 - binary_crossentropy: 0.0199 - val_loss: 0.0173 - val_binary_crossentropy: 0.0211\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01733 to 0.01707, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0160 - binary_crossentropy: 0.0196 - val_loss: 0.0171 - val_binary_crossentropy: 0.0209\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01707 to 0.01683, saving model to repeat:1_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0155 - binary_crossentropy: 0.0192 - val_loss: 0.0168 - val_binary_crossentropy: 0.0206\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0181 - val_binary_crossentropy: 0.0223\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0146 - binary_crossentropy: 0.0184 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0142 - binary_crossentropy: 0.0181 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0175 - val_binary_crossentropy: 0.0219\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0163 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0116 - binary_crossentropy: 0.0160 - val_loss: 0.0177 - val_binary_crossentropy: 0.0220\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0158 - val_loss: 0.0176 - val_binary_crossentropy: 0.0220\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0178 - val_binary_crossentropy: 0.0222\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0183 - val_binary_crossentropy: 0.0228\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0152 - val_loss: 0.0183 - val_binary_crossentropy: 0.0230\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01683\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0148 - val_loss: 0.0182 - val_binary_crossentropy: 0.0228\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01683\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0147 - val_loss: 0.0184 - val_binary_crossentropy: 0.0231\n",
      "Epoch 00024: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 1 => FOLD 4 : 0.016945491610046333\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 1 => Fold: 5\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02368, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.1896 - binary_crossentropy: 0.1910 - val_loss: 0.0237 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02368 to 0.02333, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0211 - binary_crossentropy: 0.0239 - val_loss: 0.0233 - val_binary_crossentropy: 0.0263\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02333\n",
      "147/147 - 1s - loss: 0.0197 - binary_crossentropy: 0.0228 - val_loss: 0.0245 - val_binary_crossentropy: 0.0280\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02333 to 0.02190, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0219 - val_binary_crossentropy: 0.0255\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02190 to 0.01849, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0181 - binary_crossentropy: 0.0214 - val_loss: 0.0185 - val_binary_crossentropy: 0.0220\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01849 to 0.01792, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0175 - binary_crossentropy: 0.0209 - val_loss: 0.0179 - val_binary_crossentropy: 0.0215\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01792 to 0.01763, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0176 - val_binary_crossentropy: 0.0213\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01763 to 0.01732, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0166 - binary_crossentropy: 0.0201 - val_loss: 0.0173 - val_binary_crossentropy: 0.0209\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01732 to 0.01698, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0162 - binary_crossentropy: 0.0198 - val_loss: 0.0170 - val_binary_crossentropy: 0.0206\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01698 to 0.01660, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0158 - binary_crossentropy: 0.0193 - val_loss: 0.0166 - val_binary_crossentropy: 0.0202\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01660\n",
      "147/147 - 1s - loss: 0.0153 - binary_crossentropy: 0.0190 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01660\n",
      "147/147 - 2s - loss: 0.0149 - binary_crossentropy: 0.0186 - val_loss: 0.0166 - val_binary_crossentropy: 0.0203\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01660 to 0.01657, saving model to repeat:1_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0144 - binary_crossentropy: 0.0183 - val_loss: 0.0166 - val_binary_crossentropy: 0.0204\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0179 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0135 - binary_crossentropy: 0.0175 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0129 - binary_crossentropy: 0.0171 - val_loss: 0.0169 - val_binary_crossentropy: 0.0210\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0122 - binary_crossentropy: 0.0164 - val_loss: 0.0169 - val_binary_crossentropy: 0.0209\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0162 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0160 - val_loss: 0.0171 - val_binary_crossentropy: 0.0212\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0158 - val_loss: 0.0172 - val_binary_crossentropy: 0.0215\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0155 - val_loss: 0.0176 - val_binary_crossentropy: 0.0219\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0154 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0102 - binary_crossentropy: 0.0150 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0148 - val_loss: 0.0178 - val_binary_crossentropy: 0.0223\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0148 - val_loss: 0.0180 - val_binary_crossentropy: 0.0226\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01657\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0147 - val_loss: 0.0181 - val_binary_crossentropy: 0.0227\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01657\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0145 - val_loss: 0.0183 - val_binary_crossentropy: 0.0229\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 1 => FOLD 5 : 0.016674214976120132\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 1 => Fold: 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02411, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.1878 - binary_crossentropy: 0.1892 - val_loss: 0.0241 - val_binary_crossentropy: 0.0266\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02411 to 0.02291, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0213 - binary_crossentropy: 0.0240 - val_loss: 0.0229 - val_binary_crossentropy: 0.0257\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02291\n",
      "147/147 - 1s - loss: 0.0201 - binary_crossentropy: 0.0231 - val_loss: 0.0243 - val_binary_crossentropy: 0.0268\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02291 to 0.02215, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0200 - binary_crossentropy: 0.0231 - val_loss: 0.0222 - val_binary_crossentropy: 0.0249\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02215 to 0.01963, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0196 - val_binary_crossentropy: 0.0231\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01963 to 0.01796, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0180 - val_binary_crossentropy: 0.0211\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01796 to 0.01744, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0207 - val_loss: 0.0174 - val_binary_crossentropy: 0.0209\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01744 to 0.01727, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0173 - val_binary_crossentropy: 0.0206\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01727 to 0.01699, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0166 - binary_crossentropy: 0.0200 - val_loss: 0.0170 - val_binary_crossentropy: 0.0205\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01699 to 0.01699, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0161 - binary_crossentropy: 0.0196 - val_loss: 0.0170 - val_binary_crossentropy: 0.0207\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01699 to 0.01675, saving model to repeat:1_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0168 - val_binary_crossentropy: 0.0205\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0172 - val_binary_crossentropy: 0.0212\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0148 - binary_crossentropy: 0.0185 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0144 - binary_crossentropy: 0.0182 - val_loss: 0.0171 - val_binary_crossentropy: 0.0207\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0178 - val_loss: 0.0172 - val_binary_crossentropy: 0.0215\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0135 - binary_crossentropy: 0.0175 - val_loss: 0.0171 - val_binary_crossentropy: 0.0214\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01675\n",
      "147/147 - 2s - loss: 0.0130 - binary_crossentropy: 0.0171 - val_loss: 0.0186 - val_binary_crossentropy: 0.0224\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01675\n",
      "147/147 - 2s - loss: 0.0123 - binary_crossentropy: 0.0165 - val_loss: 0.0172 - val_binary_crossentropy: 0.0215\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0162 - val_loss: 0.0175 - val_binary_crossentropy: 0.0221\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01675\n",
      "147/147 - 2s - loss: 0.0116 - binary_crossentropy: 0.0160 - val_loss: 0.0174 - val_binary_crossentropy: 0.0220\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0158 - val_loss: 0.0175 - val_binary_crossentropy: 0.0220\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0178 - val_binary_crossentropy: 0.0225\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0108 - binary_crossentropy: 0.0155 - val_loss: 0.0180 - val_binary_crossentropy: 0.0228\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01675\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0150 - val_loss: 0.0183 - val_binary_crossentropy: 0.0232\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01675\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0149 - val_loss: 0.0183 - val_binary_crossentropy: 0.0233\n",
      "Epoch 00025: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 1 => FOLD 6 : 0.01690065483504242\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 2 => Fold: 0\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02408, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.1884 - binary_crossentropy: 0.1898 - val_loss: 0.0241 - val_binary_crossentropy: 0.0265\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02408 to 0.02276, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0228 - val_binary_crossentropy: 0.0255\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02276\n",
      "147/147 - 1s - loss: 0.0201 - binary_crossentropy: 0.0231 - val_loss: 0.0231 - val_binary_crossentropy: 0.0256\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02276\n",
      "147/147 - 1s - loss: 0.0192 - binary_crossentropy: 0.0224 - val_loss: 0.0563 - val_binary_crossentropy: 0.0581\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02276 to 0.01887, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0182 - binary_crossentropy: 0.0215 - val_loss: 0.0189 - val_binary_crossentropy: 0.0219\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01887\n",
      "147/147 - 1s - loss: 0.0177 - binary_crossentropy: 0.0209 - val_loss: 0.0213 - val_binary_crossentropy: 0.0240\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01887 to 0.01809, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0172 - binary_crossentropy: 0.0205 - val_loss: 0.0181 - val_binary_crossentropy: 0.0216\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01809 to 0.01726, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0168 - binary_crossentropy: 0.0202 - val_loss: 0.0173 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01726\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0179 - val_binary_crossentropy: 0.0214\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01726\n",
      "147/147 - 1s - loss: 0.0164 - binary_crossentropy: 0.0199 - val_loss: 0.0180 - val_binary_crossentropy: 0.0219\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01726 to 0.01715, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0159 - binary_crossentropy: 0.0195 - val_loss: 0.0171 - val_binary_crossentropy: 0.0209\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01715\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0191 - val_loss: 0.0173 - val_binary_crossentropy: 0.0212\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01715 to 0.01692, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0169 - val_binary_crossentropy: 0.0207\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0147 - binary_crossentropy: 0.0185 - val_loss: 0.0174 - val_binary_crossentropy: 0.0214\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0181 - val_binary_crossentropy: 0.0225\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0138 - binary_crossentropy: 0.0178 - val_loss: 0.0172 - val_binary_crossentropy: 0.0213\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0174 - val_loss: 0.0172 - val_binary_crossentropy: 0.0213\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0130 - binary_crossentropy: 0.0172 - val_loss: 0.0177 - val_binary_crossentropy: 0.0220\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0125 - binary_crossentropy: 0.0168 - val_loss: 0.0178 - val_binary_crossentropy: 0.0223\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0162 - val_loss: 0.0175 - val_binary_crossentropy: 0.0219\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0160 - val_loss: 0.0179 - val_binary_crossentropy: 0.0224\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0157 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0156 - val_loss: 0.0183 - val_binary_crossentropy: 0.0231\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0187 - val_binary_crossentropy: 0.0236\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01692\n",
      "147/147 - 1s - loss: 0.0129 - binary_crossentropy: 0.0175 - val_loss: 0.0380 - val_binary_crossentropy: 0.0406\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01692 to 0.01691, saving model to repeat:2_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0161 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0155 - val_loss: 0.0180 - val_binary_crossentropy: 0.0226\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0153 - val_loss: 0.0184 - val_binary_crossentropy: 0.0232\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01691\n",
      "147/147 - 2s - loss: 0.0104 - binary_crossentropy: 0.0152 - val_loss: 0.0186 - val_binary_crossentropy: 0.0236\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01691\n",
      "147/147 - 2s - loss: 0.0102 - binary_crossentropy: 0.0151 - val_loss: 0.0190 - val_binary_crossentropy: 0.0241\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0151 - val_loss: 0.0194 - val_binary_crossentropy: 0.0247\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01691\n",
      "147/147 - 2s - loss: 0.0098 - binary_crossentropy: 0.0149 - val_loss: 0.0189 - val_binary_crossentropy: 0.0240\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0148 - val_loss: 0.0190 - val_binary_crossentropy: 0.0242\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01691\n",
      "147/147 - 2s - loss: 0.0095 - binary_crossentropy: 0.0147 - val_loss: 0.0191 - val_binary_crossentropy: 0.0243\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0095 - binary_crossentropy: 0.0147 - val_loss: 0.0190 - val_binary_crossentropy: 0.0242\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0147 - val_loss: 0.0193 - val_binary_crossentropy: 0.0246\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0147 - val_loss: 0.0193 - val_binary_crossentropy: 0.0247\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0146 - val_loss: 0.0192 - val_binary_crossentropy: 0.0245\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0146 - val_loss: 0.0192 - val_binary_crossentropy: 0.0245\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01691\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0092 - binary_crossentropy: 0.0146 - val_loss: 0.0194 - val_binary_crossentropy: 0.0247\n",
      "Epoch 00040: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 2 => FOLD 0 : 0.01701473882841796\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 2 => Fold: 1\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02355, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.1882 - binary_crossentropy: 0.1896 - val_loss: 0.0235 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02355 to 0.02292, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0213 - binary_crossentropy: 0.0240 - val_loss: 0.0229 - val_binary_crossentropy: 0.0259\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02292\n",
      "147/147 - 1s - loss: 0.0201 - binary_crossentropy: 0.0231 - val_loss: 0.0234 - val_binary_crossentropy: 0.0269\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02292 to 0.02049, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0191 - binary_crossentropy: 0.0223 - val_loss: 0.0205 - val_binary_crossentropy: 0.0240\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02049 to 0.01865, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0182 - binary_crossentropy: 0.0215 - val_loss: 0.0186 - val_binary_crossentropy: 0.0223\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01865 to 0.01752, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0175 - binary_crossentropy: 0.0209 - val_loss: 0.0175 - val_binary_crossentropy: 0.0210\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01752 to 0.01713, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0171 - val_binary_crossentropy: 0.0206\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01713\n",
      "147/147 - 1s - loss: 0.0166 - binary_crossentropy: 0.0200 - val_loss: 0.0172 - val_binary_crossentropy: 0.0210\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01713\n",
      "147/147 - 1s - loss: 0.0161 - binary_crossentropy: 0.0197 - val_loss: 0.0178 - val_binary_crossentropy: 0.0218\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01713 to 0.01652, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0165 - val_binary_crossentropy: 0.0202\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01652\n",
      "147/147 - 1s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0166 - val_binary_crossentropy: 0.0204\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01652\n",
      "147/147 - 2s - loss: 0.0148 - binary_crossentropy: 0.0186 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01652 to 0.01640, saving model to repeat:2_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0164 - val_binary_crossentropy: 0.0202\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0178 - val_loss: 0.0167 - val_binary_crossentropy: 0.0208\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0175 - val_loss: 0.0172 - val_binary_crossentropy: 0.0215\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0130 - binary_crossentropy: 0.0172 - val_loss: 0.0169 - val_binary_crossentropy: 0.0210\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0126 - binary_crossentropy: 0.0169 - val_loss: 0.0176 - val_binary_crossentropy: 0.0222\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0120 - binary_crossentropy: 0.0164 - val_loss: 0.0173 - val_binary_crossentropy: 0.0217\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0161 - val_loss: 0.0176 - val_binary_crossentropy: 0.0222\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0174 - val_binary_crossentropy: 0.0219\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0152 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0180 - val_binary_crossentropy: 0.0228\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0148 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0095 - binary_crossentropy: 0.0147 - val_loss: 0.0183 - val_binary_crossentropy: 0.0231\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0092 - binary_crossentropy: 0.0145 - val_loss: 0.0185 - val_binary_crossentropy: 0.0234\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01640\n",
      "147/147 - 1s - loss: 0.0088 - binary_crossentropy: 0.0142 - val_loss: 0.0185 - val_binary_crossentropy: 0.0234\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01640\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0085 - binary_crossentropy: 0.0140 - val_loss: 0.0187 - val_binary_crossentropy: 0.0238\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 2 => FOLD 1 : 0.01658672099853107\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 2 => Fold: 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02376, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.1978 - binary_crossentropy: 0.1992 - val_loss: 0.0238 - val_binary_crossentropy: 0.0264\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02376 to 0.02338, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0210 - binary_crossentropy: 0.0238 - val_loss: 0.0234 - val_binary_crossentropy: 0.0264\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02338\n",
      "147/147 - 1s - loss: 0.0198 - binary_crossentropy: 0.0228 - val_loss: 0.0237 - val_binary_crossentropy: 0.0270\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02338 to 0.02079, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0208 - val_binary_crossentropy: 0.0244\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02079 to 0.01841, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0181 - binary_crossentropy: 0.0213 - val_loss: 0.0184 - val_binary_crossentropy: 0.0219\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01841 to 0.01752, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0175 - binary_crossentropy: 0.0208 - val_loss: 0.0175 - val_binary_crossentropy: 0.0209\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01752 to 0.01737, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0174 - val_binary_crossentropy: 0.0207\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01737\n",
      "147/147 - 1s - loss: 0.0165 - binary_crossentropy: 0.0200 - val_loss: 0.0176 - val_binary_crossentropy: 0.0212\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01737 to 0.01700, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0161 - binary_crossentropy: 0.0196 - val_loss: 0.0170 - val_binary_crossentropy: 0.0205\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01700 to 0.01665, saving model to repeat:2_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0158 - binary_crossentropy: 0.0194 - val_loss: 0.0166 - val_binary_crossentropy: 0.0203\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0153 - binary_crossentropy: 0.0189 - val_loss: 0.0167 - val_binary_crossentropy: 0.0204\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0148 - binary_crossentropy: 0.0185 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0144 - binary_crossentropy: 0.0183 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0179 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0175 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0130 - binary_crossentropy: 0.0172 - val_loss: 0.0169 - val_binary_crossentropy: 0.0209\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0122 - binary_crossentropy: 0.0164 - val_loss: 0.0170 - val_binary_crossentropy: 0.0210\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0162 - val_loss: 0.0171 - val_binary_crossentropy: 0.0212\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0160 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0158 - val_loss: 0.0174 - val_binary_crossentropy: 0.0218\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0154 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01665\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01665\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0148 - val_loss: 0.0178 - val_binary_crossentropy: 0.0224\n",
      "Epoch 00024: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 2 => FOLD 2 : 0.016829755262361634\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 2 => Fold: 3\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02353, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.1842 - binary_crossentropy: 0.1856 - val_loss: 0.0235 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02353 to 0.02302, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0230 - val_binary_crossentropy: 0.0261\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02302\n",
      "147/147 - 1s - loss: 0.0200 - binary_crossentropy: 0.0230 - val_loss: 0.0232 - val_binary_crossentropy: 0.0266\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02302 to 0.02297, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0190 - binary_crossentropy: 0.0221 - val_loss: 0.0230 - val_binary_crossentropy: 0.0269\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02297 to 0.01982, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0181 - binary_crossentropy: 0.0213 - val_loss: 0.0198 - val_binary_crossentropy: 0.0237\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01982 to 0.01796, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0180 - val_binary_crossentropy: 0.0216\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01796 to 0.01746, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0175 - val_binary_crossentropy: 0.0212\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01746 to 0.01714, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0164 - binary_crossentropy: 0.0199 - val_loss: 0.0171 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01714 to 0.01693, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0195 - val_loss: 0.0169 - val_binary_crossentropy: 0.0206\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01693\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0192 - val_loss: 0.0171 - val_binary_crossentropy: 0.0210\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01693\n",
      "147/147 - 1s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0174 - val_binary_crossentropy: 0.0214\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01693\n",
      "147/147 - 2s - loss: 0.0146 - binary_crossentropy: 0.0184 - val_loss: 0.0176 - val_binary_crossentropy: 0.0218\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01693 to 0.01686, saving model to repeat:2_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01686\n",
      "147/147 - 2s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0171 - val_binary_crossentropy: 0.0212\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0124 - binary_crossentropy: 0.0166 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0120 - binary_crossentropy: 0.0163 - val_loss: 0.0176 - val_binary_crossentropy: 0.0221\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0161 - val_loss: 0.0173 - val_binary_crossentropy: 0.0214\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01686\n",
      "147/147 - 2s - loss: 0.0114 - binary_crossentropy: 0.0159 - val_loss: 0.0175 - val_binary_crossentropy: 0.0218\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0157 - val_loss: 0.0176 - val_binary_crossentropy: 0.0219\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01686\n",
      "147/147 - 2s - loss: 0.0108 - binary_crossentropy: 0.0155 - val_loss: 0.0179 - val_binary_crossentropy: 0.0224\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0179 - val_binary_crossentropy: 0.0223\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0149 - val_loss: 0.0180 - val_binary_crossentropy: 0.0225\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0148 - val_loss: 0.0184 - val_binary_crossentropy: 0.0231\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0148 - val_loss: 0.0183 - val_binary_crossentropy: 0.0228\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01686\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0146 - val_loss: 0.0183 - val_binary_crossentropy: 0.0229\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01686\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0095 - binary_crossentropy: 0.0146 - val_loss: 0.0185 - val_binary_crossentropy: 0.0231\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 2 => FOLD 3 : 0.016862037396561454\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 2 => Fold: 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02332, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.2083 - binary_crossentropy: 0.2096 - val_loss: 0.0233 - val_binary_crossentropy: 0.0260\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02332 to 0.02307, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0211 - binary_crossentropy: 0.0239 - val_loss: 0.0231 - val_binary_crossentropy: 0.0263\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02307\n",
      "147/147 - 1s - loss: 0.0197 - binary_crossentropy: 0.0227 - val_loss: 0.0244 - val_binary_crossentropy: 0.0282\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02307\n",
      "147/147 - 2s - loss: 0.0186 - binary_crossentropy: 0.0218 - val_loss: 0.0233 - val_binary_crossentropy: 0.0274\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02307 to 0.01973, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0178 - binary_crossentropy: 0.0211 - val_loss: 0.0197 - val_binary_crossentropy: 0.0236\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01973 to 0.01767, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0173 - binary_crossentropy: 0.0206 - val_loss: 0.0177 - val_binary_crossentropy: 0.0213\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01767\n",
      "147/147 - 1s - loss: 0.0168 - binary_crossentropy: 0.0202 - val_loss: 0.0186 - val_binary_crossentropy: 0.0227\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01767 to 0.01740, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0164 - binary_crossentropy: 0.0199 - val_loss: 0.0174 - val_binary_crossentropy: 0.0212\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01740 to 0.01697, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0195 - val_loss: 0.0170 - val_binary_crossentropy: 0.0207\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01697 to 0.01677, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0192 - val_loss: 0.0168 - val_binary_crossentropy: 0.0205\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0168 - val_binary_crossentropy: 0.0207\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01677 to 0.01671, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0147 - binary_crossentropy: 0.0185 - val_loss: 0.0167 - val_binary_crossentropy: 0.0207\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01671 to 0.01659, saving model to repeat:2_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0142 - binary_crossentropy: 0.0181 - val_loss: 0.0166 - val_binary_crossentropy: 0.0206\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0138 - binary_crossentropy: 0.0178 - val_loss: 0.0168 - val_binary_crossentropy: 0.0209\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0133 - binary_crossentropy: 0.0174 - val_loss: 0.0172 - val_binary_crossentropy: 0.0216\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0172 - val_binary_crossentropy: 0.0216\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0124 - binary_crossentropy: 0.0167 - val_loss: 0.0183 - val_binary_crossentropy: 0.0230\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0163 - val_loss: 0.0187 - val_binary_crossentropy: 0.0236\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0161 - val_loss: 0.0179 - val_binary_crossentropy: 0.0227\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0105 - binary_crossentropy: 0.0153 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0179 - val_binary_crossentropy: 0.0225\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0149 - val_loss: 0.0182 - val_binary_crossentropy: 0.0228\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01659\n",
      "147/147 - 2s - loss: 0.0095 - binary_crossentropy: 0.0146 - val_loss: 0.0184 - val_binary_crossentropy: 0.0232\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0145 - val_loss: 0.0188 - val_binary_crossentropy: 0.0237\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0090 - binary_crossentropy: 0.0143 - val_loss: 0.0189 - val_binary_crossentropy: 0.0240\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0085 - binary_crossentropy: 0.0139 - val_loss: 0.0189 - val_binary_crossentropy: 0.0239\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01659\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 2s - loss: 0.0083 - binary_crossentropy: 0.0138 - val_loss: 0.0190 - val_binary_crossentropy: 0.0242\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 2 => FOLD 4 : 0.016727238858251624\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 2 => Fold: 5\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02373, saving model to repeat:2_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.1901 - binary_crossentropy: 0.1915 - val_loss: 0.0237 - val_binary_crossentropy: 0.0263\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02373 to 0.02329, saving model to repeat:2_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0239 - val_loss: 0.0233 - val_binary_crossentropy: 0.0263\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02329\n",
      "147/147 - 1s - loss: 0.0199 - binary_crossentropy: 0.0229 - val_loss: 0.0234 - val_binary_crossentropy: 0.0266\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02329 to 0.02147, saving model to repeat:2_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0191 - binary_crossentropy: 0.0223 - val_loss: 0.0215 - val_binary_crossentropy: 0.0250\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02147 to 0.01901, saving model to repeat:2_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0183 - binary_crossentropy: 0.0215 - val_loss: 0.0190 - val_binary_crossentropy: 0.0224\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01901 to 0.01781, saving model to repeat:2_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0176 - binary_crossentropy: 0.0209 - val_loss: 0.0178 - val_binary_crossentropy: 0.0213\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01781\n",
      "147/147 - 1s - loss: 0.0171 - binary_crossentropy: 0.0205 - val_loss: 0.0179 - val_binary_crossentropy: 0.0214\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01781 to 0.01754, saving model to repeat:2_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0201 - val_loss: 0.0175 - val_binary_crossentropy: 0.0211\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01754\n",
      "147/147 - 1s - loss: 0.0162 - binary_crossentropy: 0.0197 - val_loss: 0.0177 - val_binary_crossentropy: 0.0214\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01754 to 0.01691, saving model to repeat:2_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0169 - val_binary_crossentropy: 0.0204\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0153 - binary_crossentropy: 0.0190 - val_loss: 0.0170 - val_binary_crossentropy: 0.0207\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01691\n",
      "147/147 - 2s - loss: 0.0149 - binary_crossentropy: 0.0186 - val_loss: 0.0172 - val_binary_crossentropy: 0.0210\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0144 - binary_crossentropy: 0.0183 - val_loss: 0.0170 - val_binary_crossentropy: 0.0208\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0140 - binary_crossentropy: 0.0179 - val_loss: 0.0173 - val_binary_crossentropy: 0.0212\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0135 - binary_crossentropy: 0.0175 - val_loss: 0.0173 - val_binary_crossentropy: 0.0213\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0130 - binary_crossentropy: 0.0171 - val_loss: 0.0174 - val_binary_crossentropy: 0.0216\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0122 - binary_crossentropy: 0.0165 - val_loss: 0.0174 - val_binary_crossentropy: 0.0213\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0162 - val_loss: 0.0175 - val_binary_crossentropy: 0.0216\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0160 - val_loss: 0.0177 - val_binary_crossentropy: 0.0219\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0158 - val_loss: 0.0178 - val_binary_crossentropy: 0.0220\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0155 - val_loss: 0.0180 - val_binary_crossentropy: 0.0225\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0182 - val_binary_crossentropy: 0.0227\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01691\n",
      "147/147 - 1s - loss: 0.0102 - binary_crossentropy: 0.0150 - val_loss: 0.0181 - val_binary_crossentropy: 0.0225\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01691\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0149 - val_loss: 0.0183 - val_binary_crossentropy: 0.0228\n",
      "Epoch 00024: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 2 => FOLD 5 : 0.017073332875368406\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 2 => Fold: 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02346, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.1999 - binary_crossentropy: 0.2013 - val_loss: 0.0235 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02346 to 0.02274, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0227 - val_binary_crossentropy: 0.0258\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02274\n",
      "147/147 - 1s - loss: 0.0201 - binary_crossentropy: 0.0231 - val_loss: 0.0229 - val_binary_crossentropy: 0.0263\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02274 to 0.02122, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0193 - binary_crossentropy: 0.0225 - val_loss: 0.0212 - val_binary_crossentropy: 0.0249\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02122 to 0.01839, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0184 - binary_crossentropy: 0.0217 - val_loss: 0.0184 - val_binary_crossentropy: 0.0220\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01839 to 0.01781, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0177 - binary_crossentropy: 0.0210 - val_loss: 0.0178 - val_binary_crossentropy: 0.0216\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01781 to 0.01718, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0171 - binary_crossentropy: 0.0205 - val_loss: 0.0172 - val_binary_crossentropy: 0.0209\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01718 to 0.01677, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0167 - binary_crossentropy: 0.0201 - val_loss: 0.0168 - val_binary_crossentropy: 0.0204\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01677 to 0.01669, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0162 - binary_crossentropy: 0.0197 - val_loss: 0.0167 - val_binary_crossentropy: 0.0204\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01669 to 0.01645, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0153 - binary_crossentropy: 0.0190 - val_loss: 0.0165 - val_binary_crossentropy: 0.0204\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01645 to 0.01639, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0149 - binary_crossentropy: 0.0186 - val_loss: 0.0164 - val_binary_crossentropy: 0.0205\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01639 to 0.01634, saving model to repeat:2_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0144 - binary_crossentropy: 0.0183 - val_loss: 0.0163 - val_binary_crossentropy: 0.0203\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0179 - val_loss: 0.0165 - val_binary_crossentropy: 0.0207\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0175 - val_loss: 0.0173 - val_binary_crossentropy: 0.0219\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0130 - binary_crossentropy: 0.0172 - val_loss: 0.0167 - val_binary_crossentropy: 0.0211\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0125 - binary_crossentropy: 0.0168 - val_loss: 0.0169 - val_binary_crossentropy: 0.0213\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0122 - binary_crossentropy: 0.0166 - val_loss: 0.0177 - val_binary_crossentropy: 0.0226\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0116 - binary_crossentropy: 0.0162 - val_loss: 0.0176 - val_binary_crossentropy: 0.0224\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0173 - val_binary_crossentropy: 0.0219\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0152 - val_loss: 0.0178 - val_binary_crossentropy: 0.0226\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01634\n",
      "147/147 - 2s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0181 - val_binary_crossentropy: 0.0230\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0149 - val_loss: 0.0180 - val_binary_crossentropy: 0.0228\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0095 - binary_crossentropy: 0.0147 - val_loss: 0.0188 - val_binary_crossentropy: 0.0241\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0092 - binary_crossentropy: 0.0145 - val_loss: 0.0185 - val_binary_crossentropy: 0.0236\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01634\n",
      "147/147 - 1s - loss: 0.0087 - binary_crossentropy: 0.0141 - val_loss: 0.0184 - val_binary_crossentropy: 0.0235\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01634\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0086 - binary_crossentropy: 0.0140 - val_loss: 0.0186 - val_binary_crossentropy: 0.0238\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 2 => FOLD 6 : 0.016451759608857197\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 3 => Fold: 0\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02369, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.1854 - binary_crossentropy: 0.1868 - val_loss: 0.0237 - val_binary_crossentropy: 0.0263\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02369 to 0.02305, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0231 - val_binary_crossentropy: 0.0261\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02305\n",
      "147/147 - 1s - loss: 0.0199 - binary_crossentropy: 0.0229 - val_loss: 0.0238 - val_binary_crossentropy: 0.0273\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02305 to 0.02087, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0209 - val_binary_crossentropy: 0.0245\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02087 to 0.02031, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0203 - val_binary_crossentropy: 0.0242\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02031 to 0.01845, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0173 - binary_crossentropy: 0.0207 - val_loss: 0.0185 - val_binary_crossentropy: 0.0222\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01845 to 0.01770, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0177 - val_binary_crossentropy: 0.0216\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01770\n",
      "147/147 - 1s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0177 - val_binary_crossentropy: 0.0215\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01770 to 0.01702, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0195 - val_loss: 0.0170 - val_binary_crossentropy: 0.0209\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01702\n",
      "147/147 - 1s - loss: 0.0154 - binary_crossentropy: 0.0191 - val_loss: 0.0171 - val_binary_crossentropy: 0.0210\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01702\n",
      "147/147 - 1s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01702 to 0.01684, saving model to repeat:3_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0146 - binary_crossentropy: 0.0184 - val_loss: 0.0168 - val_binary_crossentropy: 0.0209\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01684\n",
      "147/147 - 2s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0136 - binary_crossentropy: 0.0176 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01684\n",
      "147/147 - 2s - loss: 0.0131 - binary_crossentropy: 0.0172 - val_loss: 0.0171 - val_binary_crossentropy: 0.0214\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0126 - binary_crossentropy: 0.0169 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01684\n",
      "147/147 - 2s - loss: 0.0122 - binary_crossentropy: 0.0166 - val_loss: 0.0187 - val_binary_crossentropy: 0.0237\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0116 - binary_crossentropy: 0.0162 - val_loss: 0.0183 - val_binary_crossentropy: 0.0230\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0108 - binary_crossentropy: 0.0155 - val_loss: 0.0176 - val_binary_crossentropy: 0.0221\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0152 - val_loss: 0.0178 - val_binary_crossentropy: 0.0224\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01684\n",
      "147/147 - 2s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0183 - val_binary_crossentropy: 0.0231\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0148 - val_loss: 0.0184 - val_binary_crossentropy: 0.0231\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0147 - val_loss: 0.0184 - val_binary_crossentropy: 0.0232\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01684\n",
      "147/147 - 2s - loss: 0.0093 - binary_crossentropy: 0.0145 - val_loss: 0.0189 - val_binary_crossentropy: 0.0238\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0088 - binary_crossentropy: 0.0141 - val_loss: 0.0189 - val_binary_crossentropy: 0.0239\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01684\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0086 - binary_crossentropy: 0.0140 - val_loss: 0.0189 - val_binary_crossentropy: 0.0239\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 3 => FOLD 0 : 0.016937797655637844\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 3 => Fold: 1\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02350, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.1941 - binary_crossentropy: 0.1955 - val_loss: 0.0235 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02350 to 0.02302, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0211 - binary_crossentropy: 0.0239 - val_loss: 0.0230 - val_binary_crossentropy: 0.0261\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02302\n",
      "147/147 - 1s - loss: 0.0198 - binary_crossentropy: 0.0229 - val_loss: 0.0240 - val_binary_crossentropy: 0.0276\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02302 to 0.02113, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0188 - binary_crossentropy: 0.0220 - val_loss: 0.0211 - val_binary_crossentropy: 0.0247\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02113 to 0.01843, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0184 - val_binary_crossentropy: 0.0219\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01843 to 0.01765, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0176 - val_binary_crossentropy: 0.0211\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01765 to 0.01763, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0176 - val_binary_crossentropy: 0.0213\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01763 to 0.01715, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0165 - binary_crossentropy: 0.0200 - val_loss: 0.0171 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01715\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0196 - val_loss: 0.0185 - val_binary_crossentropy: 0.0226\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01715 to 0.01711, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0156 - binary_crossentropy: 0.0192 - val_loss: 0.0171 - val_binary_crossentropy: 0.0209\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01711\n",
      "147/147 - 1s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0173 - val_binary_crossentropy: 0.0210\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01711 to 0.01694, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0147 - binary_crossentropy: 0.0185 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01694 to 0.01678, saving model to repeat:3_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0144 - binary_crossentropy: 0.0182 - val_loss: 0.0168 - val_binary_crossentropy: 0.0207\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0138 - binary_crossentropy: 0.0178 - val_loss: 0.0173 - val_binary_crossentropy: 0.0214\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0174 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0130 - binary_crossentropy: 0.0171 - val_loss: 0.0176 - val_binary_crossentropy: 0.0220\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0124 - binary_crossentropy: 0.0167 - val_loss: 0.0180 - val_binary_crossentropy: 0.0224\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0164 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0114 - binary_crossentropy: 0.0160 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0153 - val_loss: 0.0178 - val_binary_crossentropy: 0.0222\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0102 - binary_crossentropy: 0.0151 - val_loss: 0.0183 - val_binary_crossentropy: 0.0228\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0148 - val_loss: 0.0183 - val_binary_crossentropy: 0.0230\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0147 - val_loss: 0.0185 - val_binary_crossentropy: 0.0231\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0145 - val_loss: 0.0188 - val_binary_crossentropy: 0.0235\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0091 - binary_crossentropy: 0.0144 - val_loss: 0.0189 - val_binary_crossentropy: 0.0239\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01678\n",
      "147/147 - 1s - loss: 0.0086 - binary_crossentropy: 0.0140 - val_loss: 0.0190 - val_binary_crossentropy: 0.0239\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01678\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 2s - loss: 0.0084 - binary_crossentropy: 0.0139 - val_loss: 0.0192 - val_binary_crossentropy: 0.0242\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 3 => FOLD 1 : 0.016881844487884448\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 3 => Fold: 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02402, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.2101 - binary_crossentropy: 0.2115 - val_loss: 0.0240 - val_binary_crossentropy: 0.0265\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02402 to 0.02286, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0229 - val_binary_crossentropy: 0.0256\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02286\n",
      "147/147 - 1s - loss: 0.0202 - binary_crossentropy: 0.0232 - val_loss: 0.0245 - val_binary_crossentropy: 0.0269\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02286\n",
      "147/147 - 1s - loss: 0.0192 - binary_crossentropy: 0.0224 - val_loss: 0.0232 - val_binary_crossentropy: 0.0259\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02286 to 0.01937, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0185 - binary_crossentropy: 0.0217 - val_loss: 0.0194 - val_binary_crossentropy: 0.0224\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01937 to 0.01783, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0177 - binary_crossentropy: 0.0210 - val_loss: 0.0178 - val_binary_crossentropy: 0.0210\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01783\n",
      "147/147 - 1s - loss: 0.0172 - binary_crossentropy: 0.0206 - val_loss: 0.0196 - val_binary_crossentropy: 0.0226\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01783 to 0.01720, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0201 - val_loss: 0.0172 - val_binary_crossentropy: 0.0204\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01720 to 0.01684, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0168 - val_binary_crossentropy: 0.0203\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01684 to 0.01677, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0194 - val_loss: 0.0168 - val_binary_crossentropy: 0.0201\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01677 to 0.01666, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0154 - binary_crossentropy: 0.0190 - val_loss: 0.0167 - val_binary_crossentropy: 0.0202\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01666\n",
      "147/147 - 1s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0173 - val_binary_crossentropy: 0.0206\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01666\n",
      "147/147 - 1s - loss: 0.0146 - binary_crossentropy: 0.0183 - val_loss: 0.0167 - val_binary_crossentropy: 0.0207\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01666\n",
      "147/147 - 1s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01666\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0169 - val_binary_crossentropy: 0.0211\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01666\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0169 - val_binary_crossentropy: 0.0209\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01666\n",
      "147/147 - 2s - loss: 0.0131 - binary_crossentropy: 0.0173 - val_loss: 4.3935 - val_binary_crossentropy: 4.3895\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01666 to 0.01664, saving model to repeat:3_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0131 - binary_crossentropy: 0.0172 - val_loss: 0.0166 - val_binary_crossentropy: 0.0205\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0122 - binary_crossentropy: 0.0165 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0118 - binary_crossentropy: 0.0162 - val_loss: 0.0177 - val_binary_crossentropy: 0.0223\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0160 - val_loss: 0.0185 - val_binary_crossentropy: 0.0234\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0158 - val_loss: 0.0182 - val_binary_crossentropy: 0.0230\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0156 - val_loss: 0.0182 - val_binary_crossentropy: 0.0231\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0152 - val_loss: 0.0182 - val_binary_crossentropy: 0.0231\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0186 - val_binary_crossentropy: 0.0237\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0183 - val_binary_crossentropy: 0.0232\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0149 - val_loss: 0.0184 - val_binary_crossentropy: 0.0233\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0148 - val_loss: 0.0188 - val_binary_crossentropy: 0.0238\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01664\n",
      "147/147 - 2s - loss: 0.0097 - binary_crossentropy: 0.0148 - val_loss: 0.0187 - val_binary_crossentropy: 0.0238\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0095 - binary_crossentropy: 0.0146 - val_loss: 0.0187 - val_binary_crossentropy: 0.0238\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0145 - val_loss: 0.0188 - val_binary_crossentropy: 0.0239\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01664\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0145 - val_loss: 0.0189 - val_binary_crossentropy: 0.0241\n",
      "Epoch 00032: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 3 => FOLD 2 : 0.016757706660991578\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 3 => Fold: 3\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02360, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.1961 - binary_crossentropy: 0.1975 - val_loss: 0.0236 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02360 to 0.02296, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0230 - val_binary_crossentropy: 0.0259\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02296 to 0.02289, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0200 - binary_crossentropy: 0.0230 - val_loss: 0.0229 - val_binary_crossentropy: 0.0261\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02289 to 0.02091, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0192 - binary_crossentropy: 0.0223 - val_loss: 0.0209 - val_binary_crossentropy: 0.0242\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02091 to 0.01875, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0183 - binary_crossentropy: 0.0216 - val_loss: 0.0187 - val_binary_crossentropy: 0.0223\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01875 to 0.01745, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0176 - binary_crossentropy: 0.0210 - val_loss: 0.0175 - val_binary_crossentropy: 0.0209\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01745\n",
      "147/147 - 1s - loss: 0.0172 - binary_crossentropy: 0.0206 - val_loss: 0.0175 - val_binary_crossentropy: 0.0211\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01745\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0202 - val_loss: 0.0175 - val_binary_crossentropy: 0.0214\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01745 to 0.01675, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0168 - val_binary_crossentropy: 0.0203\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01675 to 0.01672, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0158 - binary_crossentropy: 0.0194 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01672\n",
      "147/147 - 1s - loss: 0.0154 - binary_crossentropy: 0.0191 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01672 to 0.01658, saving model to repeat:3_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0166 - val_binary_crossentropy: 0.0204\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0145 - binary_crossentropy: 0.0183 - val_loss: 0.0166 - val_binary_crossentropy: 0.0205\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01658\n",
      "147/147 - 2s - loss: 0.0140 - binary_crossentropy: 0.0179 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0136 - binary_crossentropy: 0.0176 - val_loss: 0.0171 - val_binary_crossentropy: 0.0212\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01658\n",
      "147/147 - 2s - loss: 0.0131 - binary_crossentropy: 0.0172 - val_loss: 0.0168 - val_binary_crossentropy: 0.0211\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0126 - binary_crossentropy: 0.0169 - val_loss: 0.0191 - val_binary_crossentropy: 0.0241\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0121 - binary_crossentropy: 0.0165 - val_loss: 0.0172 - val_binary_crossentropy: 0.0217\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0158 - val_loss: 0.0171 - val_binary_crossentropy: 0.0215\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0156 - val_loss: 0.0173 - val_binary_crossentropy: 0.0218\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0154 - val_loss: 0.0178 - val_binary_crossentropy: 0.0224\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0150 - val_loss: 0.0178 - val_binary_crossentropy: 0.0225\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0149 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01658\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0144 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01658\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0091 - binary_crossentropy: 0.0143 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 3 => FOLD 3 : 0.016721986509319997\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 3 => Fold: 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02357, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.1872 - binary_crossentropy: 0.1887 - val_loss: 0.0236 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02357 to 0.02297, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0230 - val_binary_crossentropy: 0.0261\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02297\n",
      "147/147 - 1s - loss: 0.0200 - binary_crossentropy: 0.0230 - val_loss: 0.0235 - val_binary_crossentropy: 0.0271\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02297\n",
      "147/147 - 1s - loss: 0.0190 - binary_crossentropy: 0.0221 - val_loss: 0.0240 - val_binary_crossentropy: 0.0282\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02297 to 0.01840, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0181 - binary_crossentropy: 0.0214 - val_loss: 0.0184 - val_binary_crossentropy: 0.0221\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01840 to 0.01791, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0179 - val_binary_crossentropy: 0.0216\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01791 to 0.01757, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0176 - val_binary_crossentropy: 0.0214\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01757 to 0.01689, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0165 - binary_crossentropy: 0.0199 - val_loss: 0.0169 - val_binary_crossentropy: 0.0205\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01689\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0196 - val_loss: 0.0169 - val_binary_crossentropy: 0.0207\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01689 to 0.01670, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0156 - binary_crossentropy: 0.0192 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01670 to 0.01665, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0150 - binary_crossentropy: 0.0188 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01665 to 0.01646, saving model to repeat:3_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0147 - binary_crossentropy: 0.0185 - val_loss: 0.0165 - val_binary_crossentropy: 0.0204\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0142 - binary_crossentropy: 0.0181 - val_loss: 0.0166 - val_binary_crossentropy: 0.0204\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01646\n",
      "147/147 - 2s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0172 - val_binary_crossentropy: 0.0215\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01646\n",
      "147/147 - 2s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0167 - val_binary_crossentropy: 0.0210\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0169 - val_binary_crossentropy: 0.0211\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0167 - val_loss: 0.0190 - val_binary_crossentropy: 0.0243\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01646\n",
      "147/147 - 2s - loss: 0.0118 - binary_crossentropy: 0.0163 - val_loss: 0.0173 - val_binary_crossentropy: 0.0217\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01646\n",
      "147/147 - 2s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0174 - val_binary_crossentropy: 0.0221\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0154 - val_loss: 0.0175 - val_binary_crossentropy: 0.0221\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0152 - val_loss: 0.0180 - val_binary_crossentropy: 0.0227\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0150 - val_loss: 0.0179 - val_binary_crossentropy: 0.0226\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0148 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0095 - binary_crossentropy: 0.0147 - val_loss: 0.0184 - val_binary_crossentropy: 0.0234\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01646\n",
      "147/147 - 1s - loss: 0.0090 - binary_crossentropy: 0.0143 - val_loss: 0.0184 - val_binary_crossentropy: 0.0234\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01646\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0088 - binary_crossentropy: 0.0142 - val_loss: 0.0186 - val_binary_crossentropy: 0.0235\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 3 => FOLD 4 : 0.01660392218089807\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 3 => Fold: 5\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02359, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.1960 - binary_crossentropy: 0.1974 - val_loss: 0.0236 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02359 to 0.02299, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0211 - binary_crossentropy: 0.0239 - val_loss: 0.0230 - val_binary_crossentropy: 0.0260\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02299\n",
      "147/147 - 1s - loss: 0.0199 - binary_crossentropy: 0.0229 - val_loss: 0.0235 - val_binary_crossentropy: 0.0269\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02299 to 0.02097, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0190 - binary_crossentropy: 0.0222 - val_loss: 0.0210 - val_binary_crossentropy: 0.0244\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02097 to 0.01835, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0181 - binary_crossentropy: 0.0214 - val_loss: 0.0183 - val_binary_crossentropy: 0.0218\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01835\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0184 - val_binary_crossentropy: 0.0221\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01835 to 0.01750, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0175 - val_binary_crossentropy: 0.0211\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01750 to 0.01713, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0165 - binary_crossentropy: 0.0200 - val_loss: 0.0171 - val_binary_crossentropy: 0.0208\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01713\n",
      "147/147 - 1s - loss: 0.0161 - binary_crossentropy: 0.0196 - val_loss: 0.0176 - val_binary_crossentropy: 0.0214\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01713 to 0.01669, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0156 - binary_crossentropy: 0.0192 - val_loss: 0.0167 - val_binary_crossentropy: 0.0204\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01669\n",
      "147/147 - 2s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0170 - val_binary_crossentropy: 0.0210\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01669 to 0.01664, saving model to repeat:3_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0147 - binary_crossentropy: 0.0185 - val_loss: 0.0166 - val_binary_crossentropy: 0.0203\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0142 - binary_crossentropy: 0.0181 - val_loss: 0.0166 - val_binary_crossentropy: 0.0207\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0138 - binary_crossentropy: 0.0178 - val_loss: 0.0171 - val_binary_crossentropy: 0.0214\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0133 - binary_crossentropy: 0.0174 - val_loss: 0.0168 - val_binary_crossentropy: 0.0211\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0168 - val_binary_crossentropy: 0.0209\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0120 - binary_crossentropy: 0.0163 - val_loss: 0.0169 - val_binary_crossentropy: 0.0210\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0117 - binary_crossentropy: 0.0161 - val_loss: 0.0171 - val_binary_crossentropy: 0.0214\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0158 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0174 - val_binary_crossentropy: 0.0218\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0152 - val_loss: 0.0177 - val_binary_crossentropy: 0.0223\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0148 - val_loss: 0.0178 - val_binary_crossentropy: 0.0224\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0147 - val_loss: 0.0178 - val_binary_crossentropy: 0.0225\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01664\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0146 - val_loss: 0.0179 - val_binary_crossentropy: 0.0225\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01664\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0145 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 3 => FOLD 5 : 0.01681622767936677\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 3 => Fold: 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02346, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.1919 - binary_crossentropy: 0.1933 - val_loss: 0.0235 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02346 to 0.02284, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0228 - val_binary_crossentropy: 0.0259\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02284\n",
      "147/147 - 2s - loss: 0.0199 - binary_crossentropy: 0.0229 - val_loss: 0.0235 - val_binary_crossentropy: 0.0270\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02284 to 0.02128, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0190 - binary_crossentropy: 0.0221 - val_loss: 0.0213 - val_binary_crossentropy: 0.0250\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02128 to 0.01872, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0181 - binary_crossentropy: 0.0214 - val_loss: 0.0187 - val_binary_crossentropy: 0.0224\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01872 to 0.01767, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0175 - binary_crossentropy: 0.0208 - val_loss: 0.0177 - val_binary_crossentropy: 0.0213\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01767 to 0.01767, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0177 - val_binary_crossentropy: 0.0215\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01767 to 0.01762, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0164 - binary_crossentropy: 0.0199 - val_loss: 0.0176 - val_binary_crossentropy: 0.0215\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01762 to 0.01708, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0195 - val_loss: 0.0171 - val_binary_crossentropy: 0.0208\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01708 to 0.01661, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0191 - val_loss: 0.0166 - val_binary_crossentropy: 0.0204\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01661\n",
      "147/147 - 1s - loss: 0.0150 - binary_crossentropy: 0.0187 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01661 to 0.01654, saving model to repeat:3_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0145 - binary_crossentropy: 0.0183 - val_loss: 0.0165 - val_binary_crossentropy: 0.0204\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0140 - binary_crossentropy: 0.0179 - val_loss: 0.0166 - val_binary_crossentropy: 0.0207\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0136 - binary_crossentropy: 0.0176 - val_loss: 0.0174 - val_binary_crossentropy: 0.0218\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0131 - binary_crossentropy: 0.0172 - val_loss: 0.0169 - val_binary_crossentropy: 0.0211\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0127 - binary_crossentropy: 0.0169 - val_loss: 0.0170 - val_binary_crossentropy: 0.0212\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0162 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0159 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0157 - val_loss: 0.0173 - val_binary_crossentropy: 0.0215\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0108 - binary_crossentropy: 0.0154 - val_loss: 0.0175 - val_binary_crossentropy: 0.0220\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0105 - binary_crossentropy: 0.0152 - val_loss: 0.0177 - val_binary_crossentropy: 0.0222\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0152 - val_loss: 0.0179 - val_binary_crossentropy: 0.0226\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0098 - binary_crossentropy: 0.0147 - val_loss: 0.0178 - val_binary_crossentropy: 0.0224\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0146 - val_loss: 0.0179 - val_binary_crossentropy: 0.0225\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01654\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0145 - val_loss: 0.0182 - val_binary_crossentropy: 0.0229\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01654\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0144 - val_loss: 0.0183 - val_binary_crossentropy: 0.0230\n",
      "Epoch 00026: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 3 => FOLD 6 : 0.016626455007425402\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 4 => Fold: 0\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02377, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.1840 - binary_crossentropy: 0.1854 - val_loss: 0.0238 - val_binary_crossentropy: 0.0264\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02377 to 0.02312, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0231 - val_binary_crossentropy: 0.0262\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02312\n",
      "147/147 - 2s - loss: 0.0199 - binary_crossentropy: 0.0229 - val_loss: 0.0239 - val_binary_crossentropy: 0.0274\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02312 to 0.02118, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0189 - binary_crossentropy: 0.0221 - val_loss: 0.0212 - val_binary_crossentropy: 0.0248\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02118 to 0.01982, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0198 - val_binary_crossentropy: 0.0237\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01982 to 0.01783, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0174 - binary_crossentropy: 0.0208 - val_loss: 0.0178 - val_binary_crossentropy: 0.0215\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01783 to 0.01719, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0169 - binary_crossentropy: 0.0203 - val_loss: 0.0172 - val_binary_crossentropy: 0.0208\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01719 to 0.01706, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 1s - loss: 0.0165 - binary_crossentropy: 0.0199 - val_loss: 0.0171 - val_binary_crossentropy: 0.0207\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01706 to 0.01699, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0160 - binary_crossentropy: 0.0195 - val_loss: 0.0170 - val_binary_crossentropy: 0.0207\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01699 to 0.01667, saving model to repeat:4_Fold:0.hdf5\n",
      "147/147 - 2s - loss: 0.0155 - binary_crossentropy: 0.0191 - val_loss: 0.0167 - val_binary_crossentropy: 0.0203\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0145 - binary_crossentropy: 0.0184 - val_loss: 0.0170 - val_binary_crossentropy: 0.0210\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0142 - binary_crossentropy: 0.0181 - val_loss: 0.0168 - val_binary_crossentropy: 0.0208\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0172 - val_binary_crossentropy: 0.0210\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0173 - val_binary_crossentropy: 0.0216\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0127 - binary_crossentropy: 0.0169 - val_loss: 0.0171 - val_binary_crossentropy: 0.0213\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0162 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01667\n",
      "147/147 - 2s - loss: 0.0115 - binary_crossentropy: 0.0159 - val_loss: 0.0172 - val_binary_crossentropy: 0.0214\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0157 - val_loss: 0.0173 - val_binary_crossentropy: 0.0216\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0109 - binary_crossentropy: 0.0155 - val_loss: 0.0175 - val_binary_crossentropy: 0.0219\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0153 - val_loss: 0.0178 - val_binary_crossentropy: 0.0223\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0152 - val_loss: 0.0179 - val_binary_crossentropy: 0.0224\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01667\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0148 - val_loss: 0.0181 - val_binary_crossentropy: 0.0228\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01667\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0147 - val_loss: 0.0180 - val_binary_crossentropy: 0.0226\n",
      "Epoch 00024: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 4 => FOLD 0 : 0.01682871276179385\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 4 => Fold: 1\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02343, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.1917 - binary_crossentropy: 0.1931 - val_loss: 0.0234 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02343 to 0.02283, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0228 - val_binary_crossentropy: 0.0259\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02283\n",
      "147/147 - 1s - loss: 0.0200 - binary_crossentropy: 0.0230 - val_loss: 0.0231 - val_binary_crossentropy: 0.0265\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02283\n",
      "147/147 - 1s - loss: 0.0191 - binary_crossentropy: 0.0222 - val_loss: 0.0229 - val_binary_crossentropy: 0.0270\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02283 to 0.01919, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0182 - binary_crossentropy: 0.0215 - val_loss: 0.0192 - val_binary_crossentropy: 0.0229\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01919 to 0.01739, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0176 - binary_crossentropy: 0.0209 - val_loss: 0.0174 - val_binary_crossentropy: 0.0210\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01739\n",
      "147/147 - 1s - loss: 0.0171 - binary_crossentropy: 0.0205 - val_loss: 0.0176 - val_binary_crossentropy: 0.0214\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01739 to 0.01678, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0166 - binary_crossentropy: 0.0200 - val_loss: 0.0168 - val_binary_crossentropy: 0.0204\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01678 to 0.01669, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 2s - loss: 0.0161 - binary_crossentropy: 0.0197 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0167 - val_binary_crossentropy: 0.0206\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01669 to 0.01645, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0164 - val_binary_crossentropy: 0.0203\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01645\n",
      "147/147 - 2s - loss: 0.0148 - binary_crossentropy: 0.0186 - val_loss: 0.0165 - val_binary_crossentropy: 0.0205\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01645 to 0.01639, saving model to repeat:4_Fold:1.hdf5\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0164 - val_binary_crossentropy: 0.0205\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0138 - binary_crossentropy: 0.0178 - val_loss: 0.0167 - val_binary_crossentropy: 0.0209\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0135 - binary_crossentropy: 0.0176 - val_loss: 0.0170 - val_binary_crossentropy: 0.0213\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0129 - binary_crossentropy: 0.0171 - val_loss: 0.0167 - val_binary_crossentropy: 0.0210\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0125 - binary_crossentropy: 0.0168 - val_loss: 0.0176 - val_binary_crossentropy: 0.0223\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01639\n",
      "147/147 - 2s - loss: 0.0117 - binary_crossentropy: 0.0161 - val_loss: 0.0169 - val_binary_crossentropy: 0.0213\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0113 - binary_crossentropy: 0.0158 - val_loss: 0.0168 - val_binary_crossentropy: 0.0212\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01639\n",
      "147/147 - 2s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0172 - val_binary_crossentropy: 0.0217\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0107 - binary_crossentropy: 0.0154 - val_loss: 0.0177 - val_binary_crossentropy: 0.0225\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01639\n",
      "147/147 - 2s - loss: 0.0103 - binary_crossentropy: 0.0152 - val_loss: 0.0174 - val_binary_crossentropy: 0.0221\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0101 - binary_crossentropy: 0.0150 - val_loss: 0.0177 - val_binary_crossentropy: 0.0223\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0146 - val_loss: 0.0177 - val_binary_crossentropy: 0.0224\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0145 - val_loss: 0.0177 - val_binary_crossentropy: 0.0225\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01639\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0144 - val_loss: 0.0179 - val_binary_crossentropy: 0.0229\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01639\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0091 - binary_crossentropy: 0.0143 - val_loss: 0.0180 - val_binary_crossentropy: 0.0230\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 4 => FOLD 1 : 0.01652653658446381\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 4 => Fold: 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02417, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.2019 - binary_crossentropy: 0.2033 - val_loss: 0.0242 - val_binary_crossentropy: 0.0267\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02417 to 0.02267, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0213 - binary_crossentropy: 0.0241 - val_loss: 0.0227 - val_binary_crossentropy: 0.0256\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02267\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0242 - val_loss: 0.0357 - val_binary_crossentropy: 0.0382\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02267 to 0.02046, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0203 - binary_crossentropy: 0.0235 - val_loss: 0.0205 - val_binary_crossentropy: 0.0236\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02046 to 0.01935, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0194 - binary_crossentropy: 0.0225 - val_loss: 0.0193 - val_binary_crossentropy: 0.0226\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01935 to 0.01849, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0186 - binary_crossentropy: 0.0218 - val_loss: 0.0185 - val_binary_crossentropy: 0.0215\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01849 to 0.01777, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0213 - val_loss: 0.0178 - val_binary_crossentropy: 0.0209\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01777\n",
      "147/147 - 2s - loss: 0.0175 - binary_crossentropy: 0.0209 - val_loss: 0.0184 - val_binary_crossentropy: 0.0214\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01777 to 0.01758, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0171 - binary_crossentropy: 0.0205 - val_loss: 0.0176 - val_binary_crossentropy: 0.0207\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01758 to 0.01711, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0202 - val_loss: 0.0171 - val_binary_crossentropy: 0.0204\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01711\n",
      "147/147 - 1s - loss: 0.0164 - binary_crossentropy: 0.0198 - val_loss: 0.0177 - val_binary_crossentropy: 0.0209\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01711 to 0.01693, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0160 - binary_crossentropy: 0.0195 - val_loss: 0.0169 - val_binary_crossentropy: 0.0202\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01693 to 0.01682, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 2s - loss: 0.0161 - binary_crossentropy: 0.0196 - val_loss: 0.0168 - val_binary_crossentropy: 0.0202\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01682 to 0.01672, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0154 - binary_crossentropy: 0.0190 - val_loss: 0.0167 - val_binary_crossentropy: 0.0204\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01672 to 0.01659, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0149 - binary_crossentropy: 0.0186 - val_loss: 0.0166 - val_binary_crossentropy: 0.0203\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01659\n",
      "147/147 - 1s - loss: 0.0145 - binary_crossentropy: 0.0183 - val_loss: 0.0167 - val_binary_crossentropy: 0.0204\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01659 to 0.01653, saving model to repeat:4_Fold:2.hdf5\n",
      "147/147 - 1s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0165 - val_binary_crossentropy: 0.0204\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0176 - val_loss: 0.0166 - val_binary_crossentropy: 0.0206\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0172 - val_loss: 0.0167 - val_binary_crossentropy: 0.0208\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0169 - val_binary_crossentropy: 0.0210\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0166 - val_loss: 0.0173 - val_binary_crossentropy: 0.0217\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0159 - val_loss: 0.0172 - val_binary_crossentropy: 0.0216\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0112 - binary_crossentropy: 0.0157 - val_loss: 0.0174 - val_binary_crossentropy: 0.0220\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0108 - binary_crossentropy: 0.0154 - val_loss: 0.0177 - val_binary_crossentropy: 0.0223\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01653\n",
      "147/147 - 2s - loss: 0.0106 - binary_crossentropy: 0.0153 - val_loss: 0.0177 - val_binary_crossentropy: 0.0223\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0181 - val_binary_crossentropy: 0.0230\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0149 - val_loss: 0.0188 - val_binary_crossentropy: 0.0239\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0145 - val_loss: 0.0185 - val_binary_crossentropy: 0.0235\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0093 - binary_crossentropy: 0.0144 - val_loss: 0.0185 - val_binary_crossentropy: 0.0236\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01653\n",
      "147/147 - 1s - loss: 0.0092 - binary_crossentropy: 0.0143 - val_loss: 0.0187 - val_binary_crossentropy: 0.0238\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01653\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 2s - loss: 0.0091 - binary_crossentropy: 0.0143 - val_loss: 0.0189 - val_binary_crossentropy: 0.0241\n",
      "Epoch 00031: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 4 => FOLD 2 : 0.01668312110447423\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 4 => Fold: 3\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02364, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.1852 - binary_crossentropy: 0.1866 - val_loss: 0.0236 - val_binary_crossentropy: 0.0262\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02364 to 0.02294, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0229 - val_binary_crossentropy: 0.0259\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02294\n",
      "147/147 - 1s - loss: 0.0201 - binary_crossentropy: 0.0231 - val_loss: 0.0231 - val_binary_crossentropy: 0.0263\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02294 to 0.02109, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0192 - binary_crossentropy: 0.0223 - val_loss: 0.0211 - val_binary_crossentropy: 0.0246\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02109 to 0.01862, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0184 - binary_crossentropy: 0.0216 - val_loss: 0.0186 - val_binary_crossentropy: 0.0220\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01862\n",
      "147/147 - 1s - loss: 0.0176 - binary_crossentropy: 0.0210 - val_loss: 0.0199 - val_binary_crossentropy: 0.0237\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01862 to 0.01830, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0172 - binary_crossentropy: 0.0206 - val_loss: 0.0183 - val_binary_crossentropy: 0.0220\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01830 to 0.01740, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0167 - binary_crossentropy: 0.0201 - val_loss: 0.0174 - val_binary_crossentropy: 0.0210\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01740 to 0.01734, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0163 - binary_crossentropy: 0.0198 - val_loss: 0.0173 - val_binary_crossentropy: 0.0211\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01734 to 0.01709, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0159 - binary_crossentropy: 0.0195 - val_loss: 0.0171 - val_binary_crossentropy: 0.0208\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01709\n",
      "147/147 - 1s - loss: 0.0155 - binary_crossentropy: 0.0191 - val_loss: 0.0173 - val_binary_crossentropy: 0.0212\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01709 to 0.01706, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 2s - loss: 0.0151 - binary_crossentropy: 0.0188 - val_loss: 0.0171 - val_binary_crossentropy: 0.0209\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01706 to 0.01677, saving model to repeat:4_Fold:3.hdf5\n",
      "147/147 - 1s - loss: 0.0146 - binary_crossentropy: 0.0184 - val_loss: 0.0168 - val_binary_crossentropy: 0.0206\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0141 - binary_crossentropy: 0.0180 - val_loss: 0.0170 - val_binary_crossentropy: 0.0210\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0137 - binary_crossentropy: 0.0177 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0132 - binary_crossentropy: 0.0173 - val_loss: 0.0173 - val_binary_crossentropy: 0.0216\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0175 - val_binary_crossentropy: 0.0218\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0166 - val_loss: 0.0178 - val_binary_crossentropy: 0.0220\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0119 - binary_crossentropy: 0.0164 - val_loss: 0.0178 - val_binary_crossentropy: 0.0222\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0110 - binary_crossentropy: 0.0156 - val_loss: 0.0178 - val_binary_crossentropy: 0.0221\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0153 - val_loss: 0.0181 - val_binary_crossentropy: 0.0225\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0183 - val_binary_crossentropy: 0.0229\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0149 - val_loss: 0.0183 - val_binary_crossentropy: 0.0229\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0147 - val_loss: 0.0188 - val_binary_crossentropy: 0.0236\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0146 - val_loss: 0.0193 - val_binary_crossentropy: 0.0244\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01677\n",
      "147/147 - 1s - loss: 0.0090 - binary_crossentropy: 0.0142 - val_loss: 0.0189 - val_binary_crossentropy: 0.0238\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01677\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0088 - binary_crossentropy: 0.0141 - val_loss: 0.0191 - val_binary_crossentropy: 0.0241\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 4 => FOLD 3 : 0.016873068070566325\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 4 => Fold: 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02350, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.1855 - binary_crossentropy: 0.1869 - val_loss: 0.0235 - val_binary_crossentropy: 0.0261\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02350 to 0.02287, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0229 - val_binary_crossentropy: 0.0259\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02287\n",
      "147/147 - 1s - loss: 0.0200 - binary_crossentropy: 0.0230 - val_loss: 0.0230 - val_binary_crossentropy: 0.0263\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02287 to 0.02068, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0191 - binary_crossentropy: 0.0223 - val_loss: 0.0207 - val_binary_crossentropy: 0.0242\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02068 to 0.01910, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0182 - binary_crossentropy: 0.0215 - val_loss: 0.0191 - val_binary_crossentropy: 0.0230\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01910 to 0.01763, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0176 - binary_crossentropy: 0.0209 - val_loss: 0.0176 - val_binary_crossentropy: 0.0213\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01763\n",
      "147/147 - 1s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0179 - val_binary_crossentropy: 0.0215\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01763\n",
      "147/147 - 1s - loss: 0.0166 - binary_crossentropy: 0.0201 - val_loss: 0.0178 - val_binary_crossentropy: 0.0218\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01763 to 0.01693, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0162 - binary_crossentropy: 0.0197 - val_loss: 0.0169 - val_binary_crossentropy: 0.0208\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01693 to 0.01666, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 2s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01666\n",
      "147/147 - 1s - loss: 0.0153 - binary_crossentropy: 0.0189 - val_loss: 0.0168 - val_binary_crossentropy: 0.0207\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01666\n",
      "147/147 - 1s - loss: 0.0147 - binary_crossentropy: 0.0185 - val_loss: 0.0168 - val_binary_crossentropy: 0.0209\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01666 to 0.01655, saving model to repeat:4_Fold:4.hdf5\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0166 - val_binary_crossentropy: 0.0206\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0179 - val_loss: 0.0172 - val_binary_crossentropy: 0.0215\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01655\n",
      "147/147 - 2s - loss: 0.0134 - binary_crossentropy: 0.0175 - val_loss: 0.0167 - val_binary_crossentropy: 0.0208\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0129 - binary_crossentropy: 0.0171 - val_loss: 0.0170 - val_binary_crossentropy: 0.0213\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0125 - binary_crossentropy: 0.0168 - val_loss: 0.0173 - val_binary_crossentropy: 0.0218\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0121 - binary_crossentropy: 0.0165 - val_loss: 0.0173 - val_binary_crossentropy: 0.0219\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0161 - val_loss: 0.0180 - val_binary_crossentropy: 0.0228\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0154 - val_loss: 0.0175 - val_binary_crossentropy: 0.0220\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0179 - val_binary_crossentropy: 0.0227\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0100 - binary_crossentropy: 0.0150 - val_loss: 0.0180 - val_binary_crossentropy: 0.0228\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0097 - binary_crossentropy: 0.0148 - val_loss: 0.0182 - val_binary_crossentropy: 0.0230\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0094 - binary_crossentropy: 0.0146 - val_loss: 0.0184 - val_binary_crossentropy: 0.0234\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0092 - binary_crossentropy: 0.0145 - val_loss: 0.0186 - val_binary_crossentropy: 0.0235\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01655\n",
      "147/147 - 1s - loss: 0.0086 - binary_crossentropy: 0.0141 - val_loss: 0.0186 - val_binary_crossentropy: 0.0237\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01655\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0085 - binary_crossentropy: 0.0140 - val_loss: 0.0188 - val_binary_crossentropy: 0.0239\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 4 => FOLD 4 : 0.016595679623120273\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18812, 206)========(3136, 206)=====\n",
      "Seed: 4 => Fold: 5\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02375, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.1806 - binary_crossentropy: 0.1820 - val_loss: 0.0237 - val_binary_crossentropy: 0.0263\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02375 to 0.02336, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0211 - binary_crossentropy: 0.0239 - val_loss: 0.0234 - val_binary_crossentropy: 0.0264\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02336\n",
      "147/147 - 1s - loss: 0.0196 - binary_crossentropy: 0.0227 - val_loss: 0.0237 - val_binary_crossentropy: 0.0271\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02336 to 0.02099, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0187 - binary_crossentropy: 0.0218 - val_loss: 0.0210 - val_binary_crossentropy: 0.0244\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02099 to 0.01814, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0180 - binary_crossentropy: 0.0212 - val_loss: 0.0181 - val_binary_crossentropy: 0.0215\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01814 to 0.01754, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0174 - binary_crossentropy: 0.0207 - val_loss: 0.0175 - val_binary_crossentropy: 0.0210\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01754\n",
      "147/147 - 1s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0178 - val_binary_crossentropy: 0.0214\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01754 to 0.01753, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0165 - binary_crossentropy: 0.0200 - val_loss: 0.0175 - val_binary_crossentropy: 0.0212\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01753 to 0.01684, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 2s - loss: 0.0161 - binary_crossentropy: 0.0196 - val_loss: 0.0168 - val_binary_crossentropy: 0.0204\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0169 - val_binary_crossentropy: 0.0206\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0169 - val_binary_crossentropy: 0.0206\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01684\n",
      "147/147 - 1s - loss: 0.0148 - binary_crossentropy: 0.0185 - val_loss: 0.0169 - val_binary_crossentropy: 0.0206\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01684 to 0.01669, saving model to repeat:4_Fold:5.hdf5\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0167 - val_binary_crossentropy: 0.0205\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0138 - binary_crossentropy: 0.0178 - val_loss: 0.0171 - val_binary_crossentropy: 0.0213\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0174 - val_loss: 0.0169 - val_binary_crossentropy: 0.0210\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0128 - binary_crossentropy: 0.0170 - val_loss: 0.0170 - val_binary_crossentropy: 0.0211\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0167 - val_loss: 0.0175 - val_binary_crossentropy: 0.0217\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01669\n",
      "147/147 - 2s - loss: 0.0119 - binary_crossentropy: 0.0163 - val_loss: 0.0180 - val_binary_crossentropy: 0.0225\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01669\n",
      "147/147 - 2s - loss: 0.0114 - binary_crossentropy: 0.0160 - val_loss: 0.0180 - val_binary_crossentropy: 0.0224\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0105 - binary_crossentropy: 0.0153 - val_loss: 0.0179 - val_binary_crossentropy: 0.0225\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0102 - binary_crossentropy: 0.0150 - val_loss: 0.0180 - val_binary_crossentropy: 0.0226\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0099 - binary_crossentropy: 0.0148 - val_loss: 0.0182 - val_binary_crossentropy: 0.0228\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0096 - binary_crossentropy: 0.0147 - val_loss: 0.0184 - val_binary_crossentropy: 0.0232\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01669\n",
      "147/147 - 2s - loss: 0.0094 - binary_crossentropy: 0.0146 - val_loss: 0.0187 - val_binary_crossentropy: 0.0235\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01669\n",
      "147/147 - 2s - loss: 0.0091 - binary_crossentropy: 0.0144 - val_loss: 0.0188 - val_binary_crossentropy: 0.0237\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01669\n",
      "147/147 - 1s - loss: 0.0086 - binary_crossentropy: 0.0140 - val_loss: 0.0189 - val_binary_crossentropy: 0.0239\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01669\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0084 - binary_crossentropy: 0.0139 - val_loss: 0.0192 - val_binary_crossentropy: 0.0244\n",
      "Epoch 00027: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 4 => FOLD 5 : 0.016839145729561137\n",
      "+-+-+-+-+-+-+-+-+-+-\n",
      "======(18813, 206)========(3135, 206)=====\n",
      "Seed: 4 => Fold: 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02376, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.1855 - binary_crossentropy: 0.1869 - val_loss: 0.0238 - val_binary_crossentropy: 0.0263\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02376 to 0.02304, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0212 - binary_crossentropy: 0.0240 - val_loss: 0.0230 - val_binary_crossentropy: 0.0260\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02304\n",
      "147/147 - 1s - loss: 0.0200 - binary_crossentropy: 0.0230 - val_loss: 0.0231 - val_binary_crossentropy: 0.0263\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02304 to 0.02139, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0191 - binary_crossentropy: 0.0222 - val_loss: 0.0214 - val_binary_crossentropy: 0.0249\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02139 to 0.02106, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0182 - binary_crossentropy: 0.0214 - val_loss: 0.0211 - val_binary_crossentropy: 0.0250\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02106 to 0.01800, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0175 - binary_crossentropy: 0.0209 - val_loss: 0.0180 - val_binary_crossentropy: 0.0214\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01800 to 0.01777, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0170 - binary_crossentropy: 0.0204 - val_loss: 0.0178 - val_binary_crossentropy: 0.0213\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01777\n",
      "147/147 - 1s - loss: 0.0166 - binary_crossentropy: 0.0200 - val_loss: 0.0178 - val_binary_crossentropy: 0.0215\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01777 to 0.01708, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 2s - loss: 0.0161 - binary_crossentropy: 0.0197 - val_loss: 0.0171 - val_binary_crossentropy: 0.0205\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01708\n",
      "147/147 - 1s - loss: 0.0157 - binary_crossentropy: 0.0193 - val_loss: 0.0171 - val_binary_crossentropy: 0.0208\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01708 to 0.01704, saving model to repeat:4_Fold:6.hdf5\n",
      "147/147 - 1s - loss: 0.0152 - binary_crossentropy: 0.0189 - val_loss: 0.0170 - val_binary_crossentropy: 0.0208\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0148 - binary_crossentropy: 0.0186 - val_loss: 0.0172 - val_binary_crossentropy: 0.0210\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0143 - binary_crossentropy: 0.0182 - val_loss: 0.0171 - val_binary_crossentropy: 0.0209\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0139 - binary_crossentropy: 0.0178 - val_loss: 0.0180 - val_binary_crossentropy: 0.0224\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0134 - binary_crossentropy: 0.0175 - val_loss: 0.0172 - val_binary_crossentropy: 0.0212\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01704\n",
      "147/147 - 2s - loss: 0.0127 - binary_crossentropy: 0.0168 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0123 - binary_crossentropy: 0.0166 - val_loss: 0.0171 - val_binary_crossentropy: 0.0211\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0120 - binary_crossentropy: 0.0163 - val_loss: 0.0176 - val_binary_crossentropy: 0.0219\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0117 - binary_crossentropy: 0.0161 - val_loss: 0.0174 - val_binary_crossentropy: 0.0215\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0115 - binary_crossentropy: 0.0159 - val_loss: 0.0175 - val_binary_crossentropy: 0.0216\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0111 - binary_crossentropy: 0.0157 - val_loss: 0.0180 - val_binary_crossentropy: 0.0223\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0106 - binary_crossentropy: 0.0153 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0104 - binary_crossentropy: 0.0151 - val_loss: 0.0177 - val_binary_crossentropy: 0.0221\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01704\n",
      "147/147 - 1s - loss: 0.0103 - binary_crossentropy: 0.0151 - val_loss: 0.0179 - val_binary_crossentropy: 0.0223\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01704\n",
      "Restoring model weights from the end of the best epoch.\n",
      "147/147 - 1s - loss: 0.0102 - binary_crossentropy: 0.0150 - val_loss: 0.0179 - val_binary_crossentropy: 0.0224\n",
      "Epoch 00025: early stopping\n",
      "Model History Saved.\n",
      "OOF Metric For SEED 4 => FOLD 6 : 0.0171704603293028\n",
      "+-+-+-+-+-+-+-+-+-+-\n"
     ]
    }
   ],
   "source": [
    "N_STARTS = 5\n",
    "\n",
    "train_targets = target\n",
    "\n",
    "res = train_targets.copy()\n",
    "ss.loc[:, train_targets.columns] = 0\n",
    "res.loc[:, train_targets.columns] = 0\n",
    "\n",
    "historys = dict()\n",
    "\n",
    "#tf.random.set_seed(42)\n",
    "seed_everything(seed=42)\n",
    "for seed in range(N_STARTS):\n",
    "    for n, (tr, te) in enumerate(MultilabelStratifiedKFold(n_splits=7, random_state=seed, shuffle=True).split(train_targets, train_targets)):\n",
    "        print(f\"======{train_targets.values[tr].shape}========{train_targets.values[te].shape}=====\")\n",
    "        print(f'Seed: {seed} => Fold: {n}')\n",
    "        \n",
    "        checkpoint_path = f'repeat:{seed}_Fold:{n}.hdf5'\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, min_lr=1e-20, patience=6, verbose=1, mode='min')\n",
    "        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 1, save_best_only = True,\n",
    "                                     save_weights_only = True, mode = 'min')\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", restore_best_weights=True, patience= 14, verbose = 1)\n",
    "        \n",
    "        model = create_model(len(top_feats), SEED=seed)\n",
    "        \n",
    "        history = model.fit(train.values[tr][:, top_feats],\n",
    "                  train_targets.values[tr],\n",
    "                  validation_data=(train.values[te][:, top_feats], train_targets.values[te]),\n",
    "                  epochs=100, batch_size=128,\n",
    "                  callbacks=[reduce_lr_loss, cb_checkpt, early], verbose=2\n",
    "                 )\n",
    "        historys[f'history_seed_{seed+1}_fold_{n+1}'] = history\n",
    "        print(\"Model History Saved.\")\n",
    "        \n",
    "        model.load_weights(checkpoint_path)\n",
    "        test_predict = model.predict(test.values[:, top_feats])\n",
    "        val_predict = model.predict(train.values[te][:, top_feats])\n",
    "        \n",
    "        ss.loc[:, train_targets.columns] += test_predict\n",
    "        res.loc[te, train_targets.columns] += val_predict\n",
    "        \n",
    "        print(f'OOF Metric For SEED {seed} => FOLD {n} : {metric(train_targets.loc[te, train_targets.columns], pd.DataFrame(val_predict, columns=train_targets.columns))}')\n",
    "        print('+-' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.69594,
     "end_time": "2020-11-23T19:24:45.226380",
     "exception": false,
     "start_time": "2020-11-23T19:24:44.530440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Smoothing vs Non-Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T19:24:46.637200Z",
     "iopub.status.busy": "2020-11-23T19:24:46.636276Z",
     "iopub.status.idle": "2020-11-23T19:24:48.003264Z",
     "shell.execute_reply": "2020-11-23T19:24:48.002692Z"
    },
    "papermill": {
     "duration": 2.081424,
     "end_time": "2020-11-23T19:24:48.003380",
     "exception": false,
     "start_time": "2020-11-23T19:24:45.921956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3413f42810>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1656x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Model loss in plots\n",
    "for k,v in historys.items():\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    loss.append(v.history['loss'][:35])\n",
    "    val_loss.append(v.history['val_loss'][:35])\n",
    "    \n",
    "# Show Model loss in plots\n",
    "for k,v in historys.items():\n",
    "    bin_loss = []\n",
    "    bin_val_loss = []\n",
    "    bin_loss.append(v.history['binary_crossentropy'][:35])\n",
    "    bin_val_loss.append(v.history['val_binary_crossentropy'][:35])\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3, figsize = (23, 6))\n",
    "\n",
    "ax[0].plot(np.mean(bin_loss, axis=0), 'b', label='Smoothing Loss')\n",
    "ax[0].plot(np.mean(bin_val_loss, axis=0), 'r--', label='Smoothing Val Loss')\n",
    "ax[0].set(title=f'{somthing_rate}-Somthing Model', yscale='log', yticks=[1,1e-1,1e-2], xlabel='Epoches', ylabel='Average Logloss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.mean(loss, axis=0), 'b', label='Non-Smoothing Loss')\n",
    "ax[1].plot(np.mean(val_loss, axis=0), 'g--',label='Non-Smoothing Val Loss')\n",
    "ax[1].set(title='Non-Somthing Model', yscale='log', yticks=[1,1e-1,1e-2], xlabel='Epoches', ylabel='Average Logloss')\n",
    "ax[1].legend()\n",
    "\n",
    "\n",
    "ax[2].plot(np.mean(bin_val_loss, axis=0), 'r+', label='Smoothing Val Loss')\n",
    "ax[2].plot(np.mean(val_loss, axis=0), 'g*',label='Non-Smoothing Val Loss')\n",
    "ax[2].set(title='Somthing vs Non-Somthing Model', yscale='log', xlabel='Epoches', ylabel='Average Logloss')\n",
    "ax[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T19:24:49.735007Z",
     "iopub.status.busy": "2020-11-23T19:24:49.734099Z",
     "iopub.status.idle": "2020-11-23T19:24:49.824234Z",
     "shell.execute_reply": "2020-11-23T19:24:49.823074Z"
    },
    "papermill": {
     "duration": 0.842097,
     "end_time": "2020-11-23T19:24:49.824372",
     "exception": false,
     "start_time": "2020-11-23T19:24:48.982275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss.loc[:, train_targets.columns] /= ((n+1) * N_STARTS)\n",
    "res.loc[:, train_targets.columns] /= N_STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T19:24:51.312889Z",
     "iopub.status.busy": "2020-11-23T19:24:51.311981Z",
     "iopub.status.idle": "2020-11-23T19:24:52.578837Z",
     "shell.execute_reply": "2020-11-23T19:24:52.578284Z"
    },
    "papermill": {
     "duration": 2.022005,
     "end_time": "2020-11-23T19:24:52.578955",
     "exception": false,
     "start_time": "2020-11-23T19:24:50.556950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Metric: 0.016380999639954895\n"
     ]
    }
   ],
   "source": [
    "print(f'OOF Metric: {metric(train_targets, res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T19:24:54.518903Z",
     "iopub.status.busy": "2020-11-23T19:24:54.517954Z",
     "iopub.status.idle": "2020-11-23T19:24:56.590246Z",
     "shell.execute_reply": "2020-11-23T19:24:56.589045Z"
    },
    "papermill": {
     "duration": 3.078511,
     "end_time": "2020-11-23T19:24:56.590378",
     "exception": false,
     "start_time": "2020-11-23T19:24:53.511867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('oof_keras', res)\n",
    "np.save('pred_keras', ss)\n",
    "\n",
    "ss.to_csv('submission_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T19:24:58.077044Z",
     "iopub.status.busy": "2020-11-23T19:24:58.075774Z",
     "iopub.status.idle": "2020-11-23T19:24:59.500807Z",
     "shell.execute_reply": "2020-11-23T19:24:59.499263Z"
    },
    "papermill": {
     "duration": 2.197285,
     "end_time": "2020-11-23T19:24:59.500931",
     "exception": false,
     "start_time": "2020-11-23T19:24:57.303646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.712985,
     "end_time": "2020-11-23T19:25:00.965675",
     "exception": false,
     "start_time": "2020-11-23T19:25:00.252690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Kernel still under modification.. **<span style='color:red'>Feedbacks</span>** is also very much appreciated.\n",
    "Pls **<span style='color:red'>UPVOTE</span>**, if you find it useful. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.921955,
     "end_time": "2020-11-23T19:25:02.637906",
     "exception": false,
     "start_time": "2020-11-23T19:25:01.715951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1663.635305,
   "end_time": "2020-11-23T19:25:04.897474",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T18:57:21.262169",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
